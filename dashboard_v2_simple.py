"""
Dashboard TRI v2 Simplificado - VersÃ£o de teste
"""

import streamlit as st
import logging
import pandas as pd
import os
from auth.authentication import require_authentication, show_logout_button
from db.session_v2 import get_db_session_context
from db.crud_v2 import AssessmentCRUD, ExecutionCRUD, DatasetCRUD, ParametersSetCRUD, StudentResultCRUD
from core.item_calibration import ItemCalibrator
from core.tri_engine import TRIEngine
from core.data_processor import DataProcessor

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="Sistema TRI Profissional",
    page_icon="ğŸ“Š",
    layout="wide"
)

def show_assessments_page():
    """Exibe pÃ¡gina de gerenciamento de avaliaÃ§Ãµes"""
    st.subheader("ğŸ“‹ Gerenciamento de AvaliaÃ§Ãµes")
    
    # BotÃ£o para criar nova avaliaÃ§Ã£o
    if st.button("â• Nova AvaliaÃ§Ã£o", type="primary", key="btn_new_assessment"):
        st.session_state['show_create_assessment'] = True
    
    if st.session_state.get('show_create_assessment', False):
        show_create_assessment_form()
    
    # Lista de avaliaÃ§Ãµes
    show_assessments_list()

def show_create_assessment_form():
    """Exibe formulÃ¡rio para criar nova avaliaÃ§Ã£o"""
    st.subheader("ğŸ“ Nova AvaliaÃ§Ã£o")
    
    with st.form("create_assessment"):
        col1, col2 = st.columns(2)
        
        with col1:
            year = st.number_input("Ano", min_value=2020, max_value=2030, value=2025, step=1)
            cicle = st.selectbox("Ciclo", ["C1", "C2", "C3", "C4"])
            level = st.selectbox("NÃ­vel", ["9Âº ANO - Ens. Fundamental", "1Âº ANO - Ens. MÃ©dio", "2Âº ANO - Ens. MÃ©dio", "3Âº ANO - Ens. MÃ©dio"])
        
        with col2:
            area = st.selectbox("Ãrea do Conhecimento", [
                "Linguagens e suas Tecnologias",
                "MatemÃ¡tica e suas Tecnologias", 
                "CiÃªncias Humanas e Sociais Aplicadas",
                "CiÃªncias da Natureza e suas Tecnologias"
            ])
            description = st.text_area("DescriÃ§Ã£o", placeholder="DescriÃ§Ã£o da avaliaÃ§Ã£o")
        
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            submit = st.form_submit_button("ğŸ’¾ Criar AvaliaÃ§Ã£o", width='stretch')
        
        if submit:
            try:
                with get_db_session_context() as session:
                    assessment = AssessmentCRUD.create_assessment(
                        session, year, cicle, level, area, description
                    )
                    st.success(f"âœ… AvaliaÃ§Ã£o '{assessment.description or f'Ano {assessment.year}'}' criada com sucesso!")
                    st.session_state['show_create_assessment'] = False
                    st.rerun()
                    
            except Exception as e:
                logger.error(f"Erro ao criar avaliaÃ§Ã£o: {e}")
                st.error("Erro ao criar avaliaÃ§Ã£o")

def show_assessments_list():
    """Exibe lista de avaliaÃ§Ãµes agrupadas por Ano > Ciclo > NÃ­vel"""
    try:
        with get_db_session_context() as session:
            assessments = AssessmentCRUD.list_assessments(session)
            
            if not assessments:
                st.info("Nenhuma avaliaÃ§Ã£o cadastrada. Clique em 'Nova AvaliaÃ§Ã£o' para comeÃ§ar.")
                return
            
            st.subheader(f"ğŸ“‹ Lista de AvaliaÃ§Ãµes ({len(assessments)} encontradas)")
            
            # Agrupar avaliaÃ§Ãµes por Ano > Ciclo > NÃ­vel
            grouped_assessments = {}
            for assessment in assessments:
                year = assessment.year
                cicle = assessment.cicle or "Sem ciclo"
                level = assessment.level or "Sem nÃ­vel"
                
                if year not in grouped_assessments:
                    grouped_assessments[year] = {}
                if cicle not in grouped_assessments[year]:
                    grouped_assessments[year][cicle] = {}
                if level not in grouped_assessments[year][cicle]:
                    grouped_assessments[year][cicle][level] = []
                
                grouped_assessments[year][cicle][level].append(assessment)
            
            # Exibir agrupado
            for year in sorted(grouped_assessments.keys(), reverse=True):
                st.markdown(f"### ğŸ“… {year}")
                
                for cicle in sorted(grouped_assessments[year].keys()):
                    st.markdown(f"#### ğŸ”„ {cicle}")
                    
                    for level in sorted(grouped_assessments[year][cicle].keys()):
                        st.markdown(f"##### ğŸ“ {level}")
                        
                        for assessment in grouped_assessments[year][cicle][level]:
                            with st.expander(f"ğŸ¯ {assessment.description or f'AvaliaÃ§Ã£o {assessment.year}'}"):
                                col1, col2, col3 = st.columns([2, 1, 1])
                                
                                with col1:
                                    st.write(f"**Ano:** {assessment.year}")
                                    st.write(f"**Ciclo:** {assessment.cicle}")
                                    st.write(f"**NÃ­vel:** {assessment.level}")
                                    st.write(f"**Ãrea:** {assessment.area}")
                                    st.write(f"**Criado:** {assessment.created_at.strftime('%d/%m/%Y %H:%M')}")
                                
                                with col2:
                                    if st.button("ğŸ‘ï¸ Ver ExecuÃ§Ãµes", key=f"view_{assessment.id}"):
                                        st.session_state['selected_assessment'] = str(assessment.id)
                                        st.session_state['current_page'] = 'executions'
                                        st.rerun()
                                
                                with col3:
                                    if st.button("ğŸ—‘ï¸ Excluir", key=f"delete_{assessment.id}"):
                                        if AssessmentCRUD.delete_assessment(session, str(assessment.id)):
                                            st.success("AvaliaÃ§Ã£o excluÃ­da com sucesso!")
                                            st.rerun()
                                        else:
                                            st.error("Erro ao excluir avaliaÃ§Ã£o")
            
    except Exception as e:
        logger.error(f"Erro ao carregar lista de avaliaÃ§Ãµes: {e}")
        st.error("Erro ao carregar avaliaÃ§Ãµes")

def show_executions_page():
    """Exibe pÃ¡gina de execuÃ§Ãµes com funcionalidades da v1"""
    assessment_id = st.session_state.get('selected_assessment')
    
    if not assessment_id:
        st.error("Nenhuma avaliaÃ§Ã£o selecionada.")
        if st.button("ğŸ”™ Voltar para AvaliaÃ§Ãµes", key="btn_back_assessments"):
            st.session_state['current_page'] = 'assessments'
            st.rerun()
        return
    
    # Carregar dados da avaliaÃ§Ã£o
    try:
        with get_db_session_context() as session:
            assessment = AssessmentCRUD.get_assessment(session, assessment_id)
            if not assessment:
                st.error("AvaliaÃ§Ã£o nÃ£o encontrada.")
                return
            
            st.subheader(f"âš™ï¸ ExecuÃ§Ãµes - {assessment.description or f'AvaliaÃ§Ã£o {assessment.year}'}")
            st.info(f"ğŸ“… **{assessment.year}** | ğŸ”„ **{assessment.cicle}** | ğŸ“ **{assessment.level}** | ğŸ“š **{assessment.area}**")
            
            # BotÃ£o para voltar
            if st.button("ğŸ”™ Voltar para AvaliaÃ§Ãµes", key="btn_back_assessments"):
                st.session_state['current_page'] = 'assessments'
                st.rerun()
            
            # Tabs para as funcionalidades
            tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
                "ğŸ“ Upload de Dados",
                "ğŸ¯ Itens Ã‚ncora",
                "ğŸ”§ CalibraÃ§Ã£o de Itens", 
                "ğŸ“Š Processamento TRI",
                "ğŸ“ˆ VisualizaÃ§Ãµes",
                "ğŸ’¾ HistÃ³rico",
                "ğŸ“‹ ParÃ¢metros Salvos"
            ])
            
            with tab1:
                show_upload_data_tab(assessment_id)
            
            with tab2:
                show_anchor_items_tab(assessment_id)
            
            with tab3:
                show_calibration_tab(assessment_id)
            
            with tab4:
                show_tri_processing_tab(assessment_id)
            
            with tab5:
                show_visualizations_tab(assessment_id)
            
            with tab6:
                show_history_tab(assessment_id)
            
            with tab7:
                show_parameters_tab(assessment_id)
                
    except Exception as e:
        logger.error(f"Erro ao carregar pÃ¡gina de execuÃ§Ãµes: {e}")
        st.error("Erro ao carregar execuÃ§Ãµes")

def show_upload_data_tab(assessment_id):
    """Tab para upload de dados"""
    st.subheader("ğŸ“ Upload de Dados")
    
    # Mostrar datasets existentes
    with get_db_session_context() as session:
        existing_datasets = DatasetCRUD.list_datasets(session)
        
        if existing_datasets:
            st.success(f"âœ… {len(existing_datasets)} dataset(s) disponÃ­vel(is) para calibraÃ§Ã£o.")
            
            # Mostrar datasets existentes
            for dataset in existing_datasets:
                with st.expander(f"ğŸ“Š {dataset.name}"):
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.write(f"**Tipo:** {dataset.source_type}")
                        st.write(f"**Arquivo:** {dataset.file_name}")
                    
                    with col2:
                        st.write(f"**Criado:** {dataset.created_at.strftime('%d/%m/%Y %H:%M')}")
                    
                    with col3:
                        if st.button("ğŸ—‘ï¸ Excluir", key=f"delete_dataset_{dataset.id}"):
                            if DatasetCRUD.delete_dataset(session, dataset.id):
                                st.success("Dataset excluÃ­do com sucesso!")
                                st.rerun()
                            else:
                                st.error("Erro ao excluir dataset")
        else:
            st.info("â„¹ï¸ Nenhum dataset encontrado. FaÃ§a upload de dados para comeÃ§ar.")
    
    st.markdown("---")
    st.subheader("ğŸ“¤ Upload de Novo Dataset")
    
    uploaded_file = st.file_uploader(
        "Selecione um arquivo com respostas dos alunos",
        type=['csv', 'xlsx'],
        key="upload_data",
        help="Arquivo deve conter as respostas dos alunos (0/1 ou A/B/C/D)"
    )
    
    if uploaded_file is not None:
        try:
            # Processar arquivo
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            st.success(f"âœ… Arquivo carregado com sucesso! {len(df)} registros encontrados.")
            
            # Mostrar informaÃ§Ãµes do arquivo
            st.subheader("ğŸ“Š InformaÃ§Ãµes do Dataset")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Total de Registros", len(df))
            with col2:
                st.metric("Total de Colunas", len(df.columns))
            with col3:
                # Contar colunas que parecem ser questÃµes (numÃ©ricas ou com padrÃ£o de resposta)
                question_cols = []
                for col in df.columns:
                    if col.lower() in ['cod_pessoa', 'aluno', 'estudante', 'id']:
                        continue
                    # Verificar se Ã© coluna de questÃ£o
                    if df[col].dtype in ['object', 'int64', 'float64']:
                        unique_values = df[col].dropna().unique()
                        if len(unique_values) <= 10:  # Poucos valores Ãºnicos = provavelmente questÃ£o
                            question_cols.append(col)
                
                st.metric("QuestÃµes Identificadas", len(question_cols))
            
            # Mostrar preview
            st.subheader("ğŸ“‹ Preview dos Dados")
            st.dataframe(df.head(10))
            
            # Mostrar colunas identificadas como questÃµes
            if question_cols:
                st.subheader("ğŸ¯ QuestÃµes Identificadas")
                st.write(f"Colunas identificadas como questÃµes: {', '.join(question_cols[:10])}")
                if len(question_cols) > 10:
                    st.write(f"... e mais {len(question_cols) - 10} questÃµes")
            
            # Salvar dataset
            if st.button("ğŸ’¾ Salvar Dataset", key="btn_save_dataset"):
                with st.spinner("Salvando dataset..."):
                    try:
                        with get_db_session_context() as session:
                            dataset = DatasetCRUD.create_dataset(
                                session, 
                                name=uploaded_file.name,
                                source_type="upload",
                                file_name=uploaded_file.name
                            )
                            st.success(f"âœ… Dataset '{dataset.name}' salvo com sucesso!")
                            st.info(f"ğŸ“Š {len(question_cols)} questÃµes identificadas para calibraÃ§Ã£o")
                            st.rerun()
                            
                    except Exception as e:
                        logger.error(f"Erro ao salvar dataset: {e}")
                        st.error("Erro ao salvar dataset")
                    
        except Exception as e:
            logger.error(f"Erro ao processar arquivo: {e}")
            st.error("Erro ao processar arquivo")

def show_anchor_items_tab(assessment_id):
    """Tab para upload e gerenciamento de itens Ã¢ncora"""
    st.subheader("ğŸ¯ Itens Ã‚ncora")
    
    # Verificar se jÃ¡ existem itens Ã¢ncora para esta avaliaÃ§Ã£o
    with get_db_session_context() as session:
        existing_anchor_params = ParametersSetCRUD.get_parameters_by_assessment(session, assessment_id)
        anchor_params = [p for p in existing_anchor_params if p.is_anchor]
        
        if anchor_params:
            st.success(f"âœ… {len(anchor_params)} conjunto(s) de itens Ã¢ncora encontrado(s) para esta avaliaÃ§Ã£o.")
            
            # Mostrar itens Ã¢ncora existentes
            for param_set in anchor_params:
                with st.expander(f"ğŸ¯ {param_set.name or f'Conjunto Ã‚ncora {param_set.id}'}"):
                    st.write(f"**Criado:** {param_set.created_at.strftime('%d/%m/%Y %H:%M')}")
                    
                    # Mostrar parÃ¢metros dos itens Ã¢ncora
                    item_params = ParametersSetCRUD.get_item_parameters(session, param_set.id)
                    if item_params:
                        st.write(f"**Itens Ã¢ncora:** {len(item_params)}")
                        
                        # Criar DataFrame para mostrar parÃ¢metros
                        params_data = []
                        for param in item_params:
                            params_data.append({
                                'QuestÃ£o': param.questao,
                                'a (DiscriminaÃ§Ã£o)': param.a,
                                'b (Dificuldade)': param.b,
                                'c (Acerto ao acaso)': param.c
                            })
                        
                        df_params = pd.DataFrame(params_data)
                        st.dataframe(df_params, width='stretch')
        else:
            st.info("â„¹ï¸ Nenhum item Ã¢ncora encontrado para esta avaliaÃ§Ã£o.")
    
    st.markdown("---")
    st.subheader("ğŸ“¤ Upload de Itens Ã‚ncora")
    
    # Upload de arquivo de itens Ã¢ncora
    uploaded_anchor_file = st.file_uploader(
        "Selecione um arquivo com parÃ¢metros dos itens Ã¢ncora",
        type=['csv', 'xlsx'],
        key="upload_anchor_items",
        help="Arquivo deve conter colunas: Questao, a, b, c (ou questao, a, b, c)"
    )
    
    if uploaded_anchor_file is not None:
        try:
            # Processar arquivo
            if uploaded_anchor_file.name.endswith('.csv'):
                df_anchor = pd.read_csv(uploaded_anchor_file)
            else:
                df_anchor = pd.read_excel(uploaded_anchor_file)
            
            st.success(f"âœ… Arquivo de itens Ã¢ncora carregado! {len(df_anchor)} itens encontrados.")
            
            # Verificar colunas necessÃ¡rias (aceitar variaÃ§Ãµes de maiÃºscula/minÃºscula)
            required_columns = ['questao', 'a', 'b', 'c']
            available_columns = [col.lower() for col in df_anchor.columns]
            missing_columns = [col for col in required_columns if col not in available_columns]
            
            if missing_columns:
                st.error(f"âŒ Colunas obrigatÃ³rias nÃ£o encontradas: {missing_columns}")
                st.info("ğŸ“‹ Colunas necessÃ¡rias: Questao (ou questao), a, b, c")
                st.info(f"ğŸ“‹ Colunas encontradas no arquivo: {list(df_anchor.columns)}")
            else:
                # Mostrar preview
                st.subheader("ğŸ“‹ Preview dos Itens Ã‚ncora")
                st.dataframe(df_anchor.head(10))
                
                # Salvar itens Ã¢ncora
                if st.button("ğŸ’¾ Salvar Itens Ã‚ncora", key="btn_save_anchor_items"):
                    with st.spinner("Salvando itens Ã¢ncora..."):
                        try:
                            with get_db_session_context() as session:
                                # Criar conjunto de parÃ¢metros Ã¢ncora
                                param_set = ParametersSetCRUD.create_parameters_set(
                                    session, 
                                    name=f"Itens Ã‚ncora - {uploaded_anchor_file.name}",
                                    is_anchor=True
                                )
                                
                                # Mapear colunas (aceitar variaÃ§Ãµes de maiÃºscula/minÃºscula)
                                column_mapping = {}
                                for col in df_anchor.columns:
                                    col_lower = col.lower()
                                    if col_lower == 'questao':
                                        column_mapping['questao'] = col
                                    elif col_lower == 'a':
                                        column_mapping['a'] = col
                                    elif col_lower == 'b':
                                        column_mapping['b'] = col
                                    elif col_lower == 'c':
                                        column_mapping['c'] = col
                                
                                # Adicionar parÃ¢metros dos itens
                                for _, row in df_anchor.iterrows():
                                    ParametersSetCRUD.add_item_parameter(
                                        session,
                                        param_set.id,
                                        int(row[column_mapping['questao']]),
                                        float(row[column_mapping['a']]),
                                        float(row[column_mapping['b']]),
                                        float(row[column_mapping['c']]),
                                        is_anchor=True
                                    )
                                
                                st.success(f"âœ… {len(df_anchor)} itens Ã¢ncora salvos com sucesso!")
                                st.rerun()
                                
                        except Exception as e:
                            logger.error(f"Erro ao salvar itens Ã¢ncora: {e}")
                            st.error("Erro ao salvar itens Ã¢ncora")
                    
        except Exception as e:
            logger.error(f"Erro ao processar arquivo de itens Ã¢ncora: {e}")
            st.error("Erro ao processar arquivo de itens Ã¢ncora")

def show_calibration_tab(assessment_id):
    """Tab para calibraÃ§Ã£o de itens"""
    st.subheader("ğŸ”§ CalibraÃ§Ã£o de Itens")
    
    # Verificar se jÃ¡ existe parÃ¢metros para esta avaliaÃ§Ã£o
    with get_db_session_context() as session:
        existing_params = ParametersSetCRUD.get_parameters_by_assessment(session, assessment_id)
        non_anchor_params = [p for p in existing_params if not p.is_anchor]
        
        # Verificar se existem itens Ã¢ncora
        anchor_params = [p for p in existing_params if p.is_anchor]
        
        if non_anchor_params:
            st.warning("âš ï¸ JÃ¡ existem parÃ¢metros calibrados para esta avaliaÃ§Ã£o.")
            st.info("Se calibrar novamente, os parÃ¢metros serÃ£o atualizados.")
            
            if st.button("ğŸ”„ Recalibrar Itens", key="btn_recalibrate"):
                st.session_state['show_calibration'] = True
        else:
            st.info("â„¹ï¸ Nenhum parÃ¢metro calibrado encontrado para esta avaliaÃ§Ã£o.")
            
            if st.button("ğŸ”§ Calibrar Itens", key="btn_calibrate"):
                st.session_state['show_calibration'] = True
        
        # Mostrar status dos itens Ã¢ncora
        if anchor_params:
            st.success(f"âœ… {len(anchor_params)} conjunto(s) de itens Ã¢ncora disponÃ­vel(is) para calibraÃ§Ã£o.")
        else:
            st.warning("âš ï¸ Nenhum item Ã¢ncora encontrado. Recomenda-se fazer upload dos itens Ã¢ncora antes da calibraÃ§Ã£o.")
    
    if st.session_state.get('show_calibration', False):
        show_calibration_form(assessment_id)

def show_calibration_form(assessment_id):
    """FormulÃ¡rio de calibraÃ§Ã£o"""
    st.subheader("ğŸ”§ ConfiguraÃ§Ã£o de CalibraÃ§Ã£o")
    
    with get_db_session_context() as session:
        # Selecionar dataset
        datasets = DatasetCRUD.list_datasets(session)
        
        if not datasets:
            st.error("Nenhum dataset disponÃ­vel. FaÃ§a upload de dados primeiro.")
            return
        
        dataset_options = {f"{d.name} ({d.source_type})": d.id for d in datasets}
        selected_dataset = st.selectbox("Selecione o dataset:", list(dataset_options.keys()))
        
        # Verificar itens Ã¢ncora disponÃ­veis
        anchor_params = ParametersSetCRUD.get_parameters_by_assessment(session, assessment_id)
        anchor_params = [p for p in anchor_params if p.is_anchor]
        
        use_anchor_items = False
        selected_anchor_set = None
        
        if anchor_params:
            st.markdown("---")
            st.subheader("ğŸ¯ ConfiguraÃ§Ã£o de Itens Ã‚ncora")
            
            use_anchor_items = st.checkbox("Usar itens Ã¢ncora na calibraÃ§Ã£o", value=True)
            
            if use_anchor_items:
                anchor_options = {f"{p.name or f'Conjunto {p.id}'}": p.id for p in anchor_params}
                selected_anchor_set = st.selectbox("Selecione o conjunto de itens Ã¢ncora:", list(anchor_options.keys()))
                
                # Mostrar informaÃ§Ãµes dos itens Ã¢ncora selecionados
                if selected_anchor_set:
                    anchor_set_id = anchor_options[selected_anchor_set]
                    item_params = ParametersSetCRUD.get_item_parameters(session, anchor_set_id)
                    st.info(f"ğŸ“Š {len(item_params)} itens Ã¢ncora serÃ£o utilizados na calibraÃ§Ã£o")
        else:
            st.warning("âš ï¸ Nenhum item Ã¢ncora disponÃ­vel. A calibraÃ§Ã£o serÃ¡ realizada sem itens Ã¢ncora.")
        
        # ConfiguraÃ§Ãµes adicionais
        st.markdown("---")
        st.subheader("âš™ï¸ ConfiguraÃ§Ãµes de CalibraÃ§Ã£o")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            calibration_method = st.selectbox("MÃ©todo de CalibraÃ§Ã£o:", [
                "ML - MÃ¡xima VerossimilhanÃ§a",
                "MLF - Maximum Likelihood with Fences"
            ])
        with col2:
            max_iterations = st.number_input("MÃ¡ximo de iteraÃ§Ãµes", min_value=100, max_value=10000, value=1000, step=1)
        with col3:
            convergence_threshold = st.number_input("Limiar de convergÃªncia", min_value=0.0001, max_value=0.01, value=0.001, step=0.0001, format="%.4f")
        
        if st.button("ğŸš€ Iniciar CalibraÃ§Ã£o", key="btn_start_calibration"):
            with st.spinner("Calibrando itens..."):
                try:
                    # Aqui vocÃª implementaria a lÃ³gica de calibraÃ§Ã£o real
                    # Por enquanto, vamos simular
                    
                    # Simular progresso
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for i in range(100):
                        progress_bar.progress(i + 1)
                        status_text.text(f'Calibrando itens... {i+1}%')
                        import time
                        time.sleep(0.01)
                    
                    # Simular criaÃ§Ã£o de parÃ¢metros
                    param_set = ParametersSetCRUD.create_parameters_set(
                        session, 
                        name=f"ParÃ¢metros Calibrados - {selected_dataset}",
                        is_anchor=False
                    )
                    
                    st.success("âœ… CalibraÃ§Ã£o concluÃ­da com sucesso!")
                    st.info(f"ğŸ“Š Conjunto de parÃ¢metros criado: {param_set.name}")
                    
                    if use_anchor_items and selected_anchor_set:
                        st.info("ğŸ¯ Itens Ã¢ncora foram utilizados na calibraÃ§Ã£o")
                    
                    st.session_state['show_calibration'] = False
                    st.rerun()
                    
                except Exception as e:
                    logger.error(f"Erro na calibraÃ§Ã£o: {e}")
                    st.error("Erro durante a calibraÃ§Ã£o")

def show_tri_processing_tab(assessment_id):
    """Tab para processamento TRI"""
    st.subheader("ğŸ“Š Processamento TRI")
    
    with get_db_session_context() as session:
        # Verificar se existem parÃ¢metros calibrados
        existing_params = ParametersSetCRUD.get_parameters_by_assessment(session, assessment_id)
        non_anchor_params = [p for p in existing_params if not p.is_anchor]
        
        if not non_anchor_params:
            st.warning("âš ï¸ Nenhum parÃ¢metro calibrado encontrado. Execute a calibraÃ§Ã£o primeiro.")
            return
        
        # Verificar se existem datasets
        datasets = DatasetCRUD.list_datasets(session)
        if not datasets:
            st.warning("âš ï¸ Nenhum dataset disponÃ­vel. FaÃ§a upload de dados primeiro.")
            return
        
        st.success(f"âœ… {len(non_anchor_params)} conjunto(s) de parÃ¢metros e {len(datasets)} dataset(s) disponÃ­vel(is).")
        
        # ConfiguraÃ§Ã£o do processamento
        st.subheader("âš™ï¸ ConfiguraÃ§Ã£o do Processamento")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Selecionar parÃ¢metros
            param_options = {f"{p.name or f'Conjunto {p.id}'}": p.id for p in non_anchor_params}
            selected_params = st.selectbox("Selecione os parÃ¢metros calibrados:", list(param_options.keys()))
        
        with col2:
            # Selecionar dataset
            dataset_options = {f"{d.name} ({d.source_type})": d.id for d in datasets}
            selected_dataset = st.selectbox("Selecione o dataset:", list(dataset_options.keys()))
        
        # ConfiguraÃ§Ãµes adicionais
        st.subheader("ğŸ”§ ConfiguraÃ§Ãµes de Processamento")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            theta_bounds = st.selectbox("Limites do Theta", ["(-5, 5)", "(-4, 4)", "(-3, 3)"], index=0)
        
        with col2:
            enem_mean = st.number_input("MÃ©dia ENEM", min_value=400, max_value=600, value=500, step=1)
        
        with col3:
            enem_std = st.number_input("Desvio PadrÃ£o ENEM", min_value=50, max_value=150, value=100, step=1)
        
        # Executar processamento
        if st.button("ğŸš€ Executar Processamento TRI", key="btn_run_tri_processing"):
            with st.spinner("Processando TRI..."):
                try:
                    # Simular processamento
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    steps = [
                        "Carregando dados...",
                        "Aplicando parÃ¢metros...",
                        "Calculando proficiÃªncias...",
                        "Convertendo para escala ENEM...",
                        "Salvando resultados..."
                    ]
                    
                    for i, step in enumerate(steps):
                        progress_bar.progress((i + 1) / len(steps))
                        status_text.text(f"{step} {int((i + 1) / len(steps) * 100)}%")
                        import time
                        time.sleep(0.5)
                    
                    # Criar execuÃ§Ã£o
                    param_set_id = param_options[selected_params]
                    dataset_id = dataset_options[selected_dataset]
                    
                    execution = ExecutionCRUD.create_execution(
                        session,
                        assessment_id=assessment_id,
                        dataset_id=dataset_id,
                        parameters_set_id=param_set_id,
                        name=f"ExecuÃ§Ã£o TRI - {selected_dataset}",
                        notes=f"Processamento com parÃ¢metros {selected_params}"
                    )
                    
                    # Simular resultados
                    import random
                    results_data = []
                    for i in range(20):  # Simular 20 alunos
                        theta = random.uniform(-3, 3)
                        enem_score = max(0, min(1000, theta * 100 + 500 + random.uniform(-50, 50)))
                        acertos = random.randint(5, 20)
                        
                        results_data.append({
                            'cod_pessoa': f'ALUNO{i+1:03d}',
                            'theta': theta,
                            'enem_score': enem_score,
                            'acertos': acertos,
                            'total_itens': 20
                        })
                    
                    # Salvar resultados
                    StudentResultCRUD.bulk_create_results(session, execution.id, results_data)
                    
                    # Atualizar status da execuÃ§Ã£o
                    ExecutionCRUD.update_execution_status(session, execution.id, 'completed')
                    
                    st.success("âœ… Processamento TRI concluÃ­do com sucesso!")
                    st.info(f"ğŸ“Š ExecuÃ§Ã£o criada: {execution.name}")
                    st.info(f"ğŸ‘¥ {len(results_data)} resultados de estudantes salvos")
                    
                    # Mostrar resumo dos resultados
                    st.subheader("ğŸ“ˆ Resumo dos Resultados")
                    
                    df_results = pd.DataFrame(results_data)
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("MÃ©dia Theta", f"{df_results['theta'].mean():.3f}")
                    with col2:
                        st.metric("MÃ©dia ENEM", f"{df_results['enem_score'].mean():.1f}")
                    with col3:
                        st.metric("MÃ©dia Acertos", f"{df_results['acertos'].mean():.1f}")
                    with col4:
                        st.metric("Desvio Theta", f"{df_results['theta'].std():.3f}")
                    
                    st.rerun()
                    
                except Exception as e:
                    logger.error(f"Erro no processamento TRI: {e}")
                    st.error("Erro durante o processamento TRI")

def show_visualizations_tab(assessment_id):
    """Tab para visualizaÃ§Ãµes"""
    st.subheader("ğŸ“ˆ VisualizaÃ§Ãµes")
    
    with get_db_session_context() as session:
        # Buscar execuÃ§Ãµes com resultados
        executions = ExecutionCRUD.list_executions_by_assessment(session, assessment_id)
        executions_with_results = []
        
        for execution in executions:
            if execution.status == 'completed':
                results = StudentResultCRUD.get_results_by_execution(session, execution.id)
                if results:
                    executions_with_results.append((execution, results))
        
        if not executions_with_results:
            st.info("â„¹ï¸ Nenhuma execuÃ§Ã£o com resultados encontrada. Execute o processamento TRI primeiro.")
            return
        
        st.success(f"âœ… {len(executions_with_results)} execuÃ§Ã£o(Ãµes) com resultados disponÃ­vel(is).")
        
        # Selecionar execuÃ§Ã£o para visualizar
        execution_options = {f"{exec[0].name or f'ExecuÃ§Ã£o {exec[0].id}'} ({len(exec[1])} alunos)": i for i, exec in enumerate(executions_with_results)}
        selected_execution_idx = st.selectbox("Selecione a execuÃ§Ã£o para visualizar:", list(execution_options.keys()))
        
        if selected_execution_idx is not None:
            execution, results = executions_with_results[execution_options[selected_execution_idx]]
            
            # Converter resultados para DataFrame
            results_data = []
            for result in results:
                results_data.append({
                    'Aluno': result.cod_pessoa,
                    'Theta': result.theta,
                    'Nota ENEM': result.enem_score,
                    'Acertos': result.acertos,
                    'Total Itens': result.total_itens,
                    'Percentual Acertos': (result.acertos / result.total_itens) * 100
                })
            
            df_results = pd.DataFrame(results_data)
            
            # Tabs de visualizaÃ§Ãµes
            viz_tab1, viz_tab2, viz_tab3, viz_tab4 = st.tabs([
                "ğŸ“Š EstatÃ­sticas Gerais",
                "ğŸ“ˆ DistribuiÃ§Ãµes",
                "ğŸ¯ CorrelaÃ§Ãµes",
                "ğŸ“‹ Tabela de Dados"
            ])
            
            with viz_tab1:
                st.subheader("ğŸ“Š EstatÃ­sticas Gerais")
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Total de Alunos", len(df_results))
                    st.metric("MÃ©dia Theta", f"{df_results['Theta'].mean():.3f}")
                    st.metric("Desvio Theta", f"{df_results['Theta'].std():.3f}")
                
                with col2:
                    st.metric("MÃ©dia ENEM", f"{df_results['Nota ENEM'].mean():.1f}")
                    st.metric("Desvio ENEM", f"{df_results['Nota ENEM'].std():.1f}")
                    st.metric("Min ENEM", f"{df_results['Nota ENEM'].min():.1f}")
                
                with col3:
                    st.metric("Max ENEM", f"{df_results['Nota ENEM'].max():.1f}")
                    st.metric("MÃ©dia Acertos", f"{df_results['Acertos'].mean():.1f}")
                    st.metric("Desvio Acertos", f"{df_results['Acertos'].std():.1f}")
                
                with col4:
                    st.metric("MÃ©dia % Acertos", f"{df_results['Percentual Acertos'].mean():.1f}%")
                    st.metric("Min % Acertos", f"{df_results['Percentual Acertos'].min():.1f}%")
                    st.metric("Max % Acertos", f"{df_results['Percentual Acertos'].max():.1f}%")
            
            with viz_tab2:
                st.subheader("ğŸ“ˆ DistribuiÃ§Ãµes")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("DistribuiÃ§Ã£o do Theta")
                    import plotly.express as px
                    fig_theta = px.histogram(df_results, x='Theta', nbins=20, title="DistribuiÃ§Ã£o do Theta")
                    st.plotly_chart(fig_theta, use_container_width=True)
                
                with col2:
                    st.subheader("DistribuiÃ§Ã£o da Nota ENEM")
                    fig_enem = px.histogram(df_results, x='Nota ENEM', nbins=20, title="DistribuiÃ§Ã£o da Nota ENEM")
                    st.plotly_chart(fig_enem, use_container_width=True)
                
                col3, col4 = st.columns(2)
                
                with col3:
                    st.subheader("DistribuiÃ§Ã£o dos Acertos")
                    fig_acertos = px.histogram(df_results, x='Acertos', nbins=20, title="DistribuiÃ§Ã£o dos Acertos")
                    st.plotly_chart(fig_acertos, use_container_width=True)
                
                with col4:
                    st.subheader("DistribuiÃ§Ã£o % Acertos")
                    fig_percent = px.histogram(df_results, x='Percentual Acertos', nbins=20, title="DistribuiÃ§Ã£o % Acertos")
                    st.plotly_chart(fig_percent, use_container_width=True)
            
            with viz_tab3:
                st.subheader("ğŸ¯ CorrelaÃ§Ãµes")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("Theta vs Nota ENEM")
                    fig_corr1 = px.scatter(df_results, x='Theta', y='Nota ENEM', 
                                         title="CorrelaÃ§Ã£o: Theta vs Nota ENEM",
                                         trendline="ols")
                    st.plotly_chart(fig_corr1, use_container_width=True)
                    
                    # Calcular correlaÃ§Ã£o
                    corr_theta_enem = df_results['Theta'].corr(df_results['Nota ENEM'])
                    st.metric("CorrelaÃ§Ã£o Theta-ENEM", f"{corr_theta_enem:.3f}")
                
                with col2:
                    st.subheader("Acertos vs Nota ENEM")
                    fig_corr2 = px.scatter(df_results, x='Acertos', y='Nota ENEM',
                                         title="CorrelaÃ§Ã£o: Acertos vs Nota ENEM",
                                         trendline="ols")
                    st.plotly_chart(fig_corr2, use_container_width=True)
                    
                    # Calcular correlaÃ§Ã£o
                    corr_acertos_enem = df_results['Acertos'].corr(df_results['Nota ENEM'])
                    st.metric("CorrelaÃ§Ã£o Acertos-ENEM", f"{corr_acertos_enem:.3f}")
                
                col3, col4 = st.columns(2)
                
                with col3:
                    st.subheader("Theta vs Acertos")
                    fig_corr3 = px.scatter(df_results, x='Theta', y='Acertos',
                                         title="CorrelaÃ§Ã£o: Theta vs Acertos",
                                         trendline="ols")
                    st.plotly_chart(fig_corr3, use_container_width=True)
                    
                    # Calcular correlaÃ§Ã£o
                    corr_theta_acertos = df_results['Theta'].corr(df_results['Acertos'])
                    st.metric("CorrelaÃ§Ã£o Theta-Acertos", f"{corr_theta_acertos:.3f}")
                
                with col4:
                    st.subheader("Matriz de CorrelaÃ§Ã£o")
                    corr_matrix = df_results[['Theta', 'Nota ENEM', 'Acertos', 'Percentual Acertos']].corr()
                    fig_matrix = px.imshow(corr_matrix, text_auto=True, aspect="auto", 
                                         title="Matriz de CorrelaÃ§Ã£o")
                    st.plotly_chart(fig_matrix, use_container_width=True)
            
            with viz_tab4:
                st.subheader("ğŸ“‹ Tabela de Dados")
                
                # Filtros
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    min_theta_val = df_results['Theta'].min()
                    max_theta_val = df_results['Theta'].max()
                    min_theta = st.number_input("Theta MÃ­nimo", value=float(min_theta_val) if not pd.isna(min_theta_val) else -3.0, step=0.1)
                    max_theta = st.number_input("Theta MÃ¡ximo", value=float(max_theta_val) if not pd.isna(max_theta_val) else 3.0, step=0.1)
                
                with col2:
                    min_enem_val = df_results['Nota ENEM'].min()
                    max_enem_val = df_results['Nota ENEM'].max()
                    min_enem = st.number_input("ENEM MÃ­nimo", value=float(min_enem_val) if not pd.isna(min_enem_val) else 0.0, step=10.0)
                    max_enem = st.number_input("ENEM MÃ¡ximo", value=float(max_enem_val) if not pd.isna(max_enem_val) else 1000.0, step=10.0)
                
                with col3:
                    min_acertos_val = df_results['Acertos'].min()
                    max_acertos_val = df_results['Acertos'].max()
                    min_acertos = st.number_input("Acertos MÃ­nimo", value=int(min_acertos_val) if not pd.isna(min_acertos_val) else 0, step=1)
                    max_acertos = st.number_input("Acertos MÃ¡ximo", value=int(max_acertos_val) if not pd.isna(max_acertos_val) else 20, step=1)
                
                # Aplicar filtros
                filtered_df = df_results[
                    (df_results['Theta'] >= min_theta) & (df_results['Theta'] <= max_theta) &
                    (df_results['Nota ENEM'] >= min_enem) & (df_results['Nota ENEM'] <= max_enem) &
                    (df_results['Acertos'] >= min_acertos) & (df_results['Acertos'] <= max_acertos)
                ]
                
                st.write(f"**{len(filtered_df)} alunos** (de {len(df_results)} total)")
                
                # Mostrar tabela
                st.dataframe(filtered_df, width='stretch')
                
                # BotÃ£o de download
                csv_data = filtered_df.to_csv(index=False)
                st.download_button(
                    label="ğŸ“¥ Download CSV",
                    data=csv_data,
                    file_name=f"resultados_tri_{execution.id}.csv",
                    mime="text/csv",
                    key=f"download_results_{execution.id}"
                )

def show_history_tab(assessment_id):
    """Tab para histÃ³rico"""
    st.subheader("ğŸ’¾ HistÃ³rico de ExecuÃ§Ãµes")
    
    with get_db_session_context() as session:
        executions = ExecutionCRUD.list_executions_by_assessment(session, assessment_id)
        
        if not executions:
            st.info("Nenhuma execuÃ§Ã£o encontrada para esta avaliaÃ§Ã£o.")
            return
        
        st.success(f"âœ… {len(executions)} execuÃ§Ã£o(Ãµes) encontrada(s).")
        
        # Filtros
        st.subheader("ğŸ” Filtros")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            status_filter = st.selectbox("Filtrar por Status", ["Todos", "pending", "running", "completed", "failed"])
        
        with col2:
            # Buscar datasets para mostrar nomes
            datasets = DatasetCRUD.list_datasets(session)
            dataset_dict = {d.id: d.name for d in datasets}
            
            # Buscar parÃ¢metros para mostrar nomes
            params_sets = ParametersSetCRUD.list_parameters_sets(session)
            params_dict = {p.id: p.name for p in params_sets}
        
        with col3:
            sort_by = st.selectbox("Ordenar por", ["Data (Mais Recente)", "Data (Mais Antigo)", "Status", "Nome"])
        
        # Aplicar filtros
        filtered_executions = executions
        
        if status_filter != "Todos":
            filtered_executions = [e for e in filtered_executions if e.status == status_filter]
        
        # Ordenar
        if sort_by == "Data (Mais Recente)":
            filtered_executions.sort(key=lambda x: x.created_at, reverse=True)
        elif sort_by == "Data (Mais Antigo)":
            filtered_executions.sort(key=lambda x: x.created_at)
        elif sort_by == "Status":
            filtered_executions.sort(key=lambda x: x.status)
        elif sort_by == "Nome":
            filtered_executions.sort(key=lambda x: x.name or f"ExecuÃ§Ã£o {x.id}")
        
        st.write(f"**{len(filtered_executions)} execuÃ§Ã£o(Ãµes)** (de {len(executions)} total)")
        
        # Mostrar execuÃ§Ãµes
        for execution in filtered_executions:
            # Buscar resultados se existirem
            results = StudentResultCRUD.get_results_by_execution(session, execution.id)
            
            # Status colorido
            status_color = {
                'pending': 'ğŸŸ¡',
                'running': 'ğŸ”µ', 
                'completed': 'ğŸŸ¢',
                'failed': 'ğŸ”´'
            }.get(execution.status, 'âšª')
            
            with st.expander(f"{status_color} {execution.name or f'ExecuÃ§Ã£o {execution.id}'} - {execution.status.upper()}"):
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.write(f"**Status:** {execution.status}")
                    st.write(f"**Criado:** {execution.created_at.strftime('%d/%m/%Y %H:%M')}")
                    if execution.notes:
                        st.write(f"**Notas:** {execution.notes}")
                
                with col2:
                    dataset_name = dataset_dict.get(execution.dataset_id, f"ID: {execution.dataset_id}")
                    st.write(f"**Dataset:** {dataset_name}")
                    
                    params_name = params_dict.get(execution.parameters_set_id, f"ID: {execution.parameters_set_id}")
                    st.write(f"**ParÃ¢metros:** {params_name}")
                
                with col3:
                    if results:
                        st.write(f"**Resultados:** {len(results)} alunos")
                        
                        # Calcular estatÃ­sticas bÃ¡sicas
                        if results:
                            thetas = [r.theta for r in results]
                            enem_scores = [r.enem_score for r in results]
                            
                            st.write(f"**MÃ©dia Theta:** {sum(thetas)/len(thetas):.3f}")
                            st.write(f"**MÃ©dia ENEM:** {sum(enem_scores)/len(enem_scores):.1f}")
                    else:
                        st.write("**Resultados:** Nenhum")
                
                with col4:
                    # AÃ§Ãµes
                    if execution.status == 'completed' and results:
                        if st.button("ğŸ“Š Ver VisualizaÃ§Ãµes", key=f"view_viz_{execution.id}"):
                            st.session_state['selected_execution_for_viz'] = execution.id
                            st.session_state['current_viz_tab'] = 'visualizations'
                            st.rerun()
                    
                    if st.button("ğŸ—‘ï¸ Excluir", key=f"delete_exec_{execution.id}"):
                        if ExecutionCRUD.delete_execution(session, execution.id):
                            st.success("ExecuÃ§Ã£o excluÃ­da com sucesso!")
                            st.rerun()
                        else:
                            st.error("Erro ao excluir execuÃ§Ã£o")
                    
                    # BotÃ£o para reprocessar se falhou
                    if execution.status == 'failed':
                        if st.button("ğŸ”„ Reprocessar", key=f"reprocess_{execution.id}"):
                            ExecutionCRUD.update_execution_status(session, execution.id, 'pending')
                            st.success("ExecuÃ§Ã£o marcada para reprocessamento!")
                            st.rerun()
        
        # EstatÃ­sticas gerais
        st.subheader("ğŸ“Š EstatÃ­sticas Gerais")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_executions = len(executions)
            st.metric("Total de ExecuÃ§Ãµes", total_executions)
        
        with col2:
            completed_executions = len([e for e in executions if e.status == 'completed'])
            st.metric("ExecuÃ§Ãµes ConcluÃ­das", completed_executions)
        
        with col3:
            pending_executions = len([e for e in executions if e.status in ['pending', 'running']])
            st.metric("ExecuÃ§Ãµes Pendentes", pending_executions)
        
        with col4:
            failed_executions = len([e for e in executions if e.status == 'failed'])
            st.metric("ExecuÃ§Ãµes Falharam", failed_executions)
        
        # GrÃ¡fico de status
        if executions:
            import plotly.express as px
            
            status_counts = {}
            for execution in executions:
                status_counts[execution.status] = status_counts.get(execution.status, 0) + 1
            
            df_status = pd.DataFrame(list(status_counts.items()), columns=['Status', 'Quantidade'])
            fig_status = px.pie(df_status, values='Quantidade', names='Status', 
                              title="DistribuiÃ§Ã£o de Status das ExecuÃ§Ãµes")
            st.plotly_chart(fig_status, use_container_width=True)

def show_parameters_tab(assessment_id):
    """Tab para parÃ¢metros salvos"""
    st.subheader("ğŸ“‹ ParÃ¢metros Salvos")
    
    with get_db_session_context() as session:
        params_sets = ParametersSetCRUD.get_parameters_by_assessment(session, assessment_id)
        
        if not params_sets:
            st.info("Nenhum parÃ¢metro salvo para esta avaliaÃ§Ã£o.")
            return
        
        st.success(f"âœ… {len(params_sets)} conjunto(s) de parÃ¢metros encontrado(s).")
        
        # Separar parÃ¢metros Ã¢ncora dos calibrados
        anchor_params = [p for p in params_sets if p.is_anchor]
        calibrated_params = [p for p in params_sets if not p.is_anchor]
        
        # Tabs para diferentes tipos de parÃ¢metros
        param_tab1, param_tab2 = st.tabs([
            f"ğŸ¯ Itens Ã‚ncora ({len(anchor_params)})",
            f"ğŸ”§ ParÃ¢metros Calibrados ({len(calibrated_params)})"
        ])
        
        with param_tab1:
            if anchor_params:
                st.subheader("ğŸ¯ ParÃ¢metros dos Itens Ã‚ncora")
                
                for param_set in anchor_params:
                    with st.expander(f"ğŸ¯ {param_set.name or f'Conjunto Ã‚ncora {param_set.id}'}"):
                        col1, col2, col3 = st.columns([2, 1, 1])
                        
                        with col1:
                            st.write(f"**Criado:** {param_set.created_at.strftime('%d/%m/%Y %H:%M')}")
                            st.write(f"**Tipo:** Itens Ã‚ncora")
                        
                        with col2:
                            item_params = ParametersSetCRUD.get_item_parameters(session, param_set.id)
                            st.write(f"**Itens:** {len(item_params)}")
                        
                        with col3:
                            if st.button("ğŸ—‘ï¸ Excluir", key=f"delete_anchor_{param_set.id}"):
                                if ParametersSetCRUD.delete_parameters_set(session, param_set.id):
                                    st.success("Conjunto de parÃ¢metros excluÃ­do!")
                                    st.rerun()
                                else:
                                    st.error("Erro ao excluir parÃ¢metros")
                        
                        # Mostrar parÃ¢metros dos itens Ã¢ncora
                        if item_params:
                            # Criar DataFrame para mostrar parÃ¢metros
                            params_data = []
                            for param in item_params:
                                params_data.append({
                                    'QuestÃ£o': param.questao,
                                    'a (DiscriminaÃ§Ã£o)': param.a,
                                    'b (Dificuldade)': param.b,
                                    'c (Acerto ao acaso)': param.c
                                })
                            
                            df_params = pd.DataFrame(params_data)
                            st.dataframe(df_params, width='stretch')
                            
                            # EstatÃ­sticas dos parÃ¢metros Ã¢ncora
                            st.subheader("ğŸ“Š EstatÃ­sticas dos ParÃ¢metros Ã‚ncora")
                            
                            col1, col2, col3, col4 = st.columns(4)
                            
                            with col1:
                                st.metric("MÃ©dia a", f"{df_params['a (DiscriminaÃ§Ã£o)'].mean():.3f}")
                                st.metric("Desvio a", f"{df_params['a (DiscriminaÃ§Ã£o)'].std():.3f}")
                            
                            with col2:
                                st.metric("MÃ©dia b", f"{df_params['b (Dificuldade)'].mean():.3f}")
                                st.metric("Desvio b", f"{df_params['b (Dificuldade)'].std():.3f}")
                            
                            with col3:
                                st.metric("MÃ©dia c", f"{df_params['c (Acerto ao acaso)'].mean():.3f}")
                                st.metric("Desvio c", f"{df_params['c (Acerto ao acaso)'].std():.3f}")
                            
                            with col4:
                                st.metric("Min a", f"{df_params['a (DiscriminaÃ§Ã£o)'].min():.3f}")
                                st.metric("Max a", f"{df_params['a (DiscriminaÃ§Ã£o)'].max():.3f}")
                            
                            # GrÃ¡ficos dos parÃ¢metros Ã¢ncora
                            import plotly.express as px
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                fig_a = px.histogram(df_params, x='a (DiscriminaÃ§Ã£o)', nbins=10, 
                                                   title="DistribuiÃ§Ã£o do ParÃ¢metro a (DiscriminaÃ§Ã£o)")
                                st.plotly_chart(fig_a, use_container_width=True)
                            
                            with col2:
                                fig_b = px.histogram(df_params, x='b (Dificuldade)', nbins=10,
                                                   title="DistribuiÃ§Ã£o do ParÃ¢metro b (Dificuldade)")
                                st.plotly_chart(fig_b, use_container_width=True)
                            
                            col3, col4 = st.columns(2)
                            
                            with col3:
                                fig_c = px.histogram(df_params, x='c (Acerto ao acaso)', nbins=10,
                                                   title="DistribuiÃ§Ã£o do ParÃ¢metro c (Acerto ao acaso)")
                                st.plotly_chart(fig_c, use_container_width=True)
                            
                            with col4:
                                # Scatter plot a vs b
                                fig_scatter = px.scatter(df_params, x='b (Dificuldade)', y='a (DiscriminaÃ§Ã£o)',
                                                       title="CorrelaÃ§Ã£o: Dificuldade vs DiscriminaÃ§Ã£o",
                                                       hover_data=['QuestÃ£o'])
                                st.plotly_chart(fig_scatter, use_container_width=True)
                            
                            # BotÃ£o de download
                            csv_data = df_params.to_csv(index=False)
                            st.download_button(
                                label="ğŸ“¥ Download ParÃ¢metros Ã‚ncora",
                                data=csv_data,
                                file_name=f"parametros_ancora_{param_set.id}.csv",
                                mime="text/csv",
                                key=f"download_anchor_{param_set.id}"
                            )
            else:
                st.info("â„¹ï¸ Nenhum parÃ¢metro Ã¢ncora encontrado.")
        
        with param_tab2:
            if calibrated_params:
                st.subheader("ğŸ”§ ParÃ¢metros Calibrados")
                
                for param_set in calibrated_params:
                    with st.expander(f"ğŸ”§ {param_set.name or f'Conjunto Calibrado {param_set.id}'}"):
                        col1, col2, col3 = st.columns([2, 1, 1])
                        
                        with col1:
                            st.write(f"**Criado:** {param_set.created_at.strftime('%d/%m/%Y %H:%M')}")
                            st.write(f"**Tipo:** ParÃ¢metros Calibrados")
                        
                        with col2:
                            item_params = ParametersSetCRUD.get_item_parameters(session, param_set.id)
                            st.write(f"**Itens:** {len(item_params)}")
                        
                        with col3:
                            if st.button("ğŸ—‘ï¸ Excluir", key=f"delete_calibrated_{param_set.id}"):
                                if ParametersSetCRUD.delete_parameters_set(session, param_set.id):
                                    st.success("Conjunto de parÃ¢metros excluÃ­do!")
                                    st.rerun()
                                else:
                                    st.error("Erro ao excluir parÃ¢metros")
                        
                        # Mostrar parÃ¢metros calibrados
                        if item_params:
                            # Criar DataFrame para mostrar parÃ¢metros
                            params_data = []
                            for param in item_params:
                                params_data.append({
                                    'QuestÃ£o': param.questao,
                                    'a (DiscriminaÃ§Ã£o)': param.a,
                                    'b (Dificuldade)': param.b,
                                    'c (Acerto ao acaso)': param.c,
                                    'Ã‰ Ã‚ncora': 'Sim' if param.is_anchor else 'NÃ£o'
                                })
                            
                            df_params = pd.DataFrame(params_data)
                            st.dataframe(df_params, width='stretch')
                            
                            # EstatÃ­sticas dos parÃ¢metros calibrados
                            st.subheader("ğŸ“Š EstatÃ­sticas dos ParÃ¢metros Calibrados")
                            
                            col1, col2, col3, col4 = st.columns(4)
                            
                            with col1:
                                st.metric("MÃ©dia a", f"{df_params['a (DiscriminaÃ§Ã£o)'].mean():.3f}")
                                st.metric("Desvio a", f"{df_params['a (DiscriminaÃ§Ã£o)'].std():.3f}")
                            
                            with col2:
                                st.metric("MÃ©dia b", f"{df_params['b (Dificuldade)'].mean():.3f}")
                                st.metric("Desvio b", f"{df_params['b (Dificuldade)'].std():.3f}")
                            
                            with col3:
                                st.metric("MÃ©dia c", f"{df_params['c (Acerto ao acaso)'].mean():.3f}")
                                st.metric("Desvio c", f"{df_params['c (Acerto ao acaso)'].std():.3f}")
                            
                            with col4:
                                anchor_count = len(df_params[df_params['Ã‰ Ã‚ncora'] == 'Sim'])
                                st.metric("Itens Ã‚ncora", anchor_count)
                                st.metric("Itens Calibrados", len(df_params) - anchor_count)
                            
                            # GrÃ¡ficos dos parÃ¢metros calibrados
                            import plotly.express as px
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                fig_a = px.histogram(df_params, x='a (DiscriminaÃ§Ã£o)', nbins=15, 
                                                   title="DistribuiÃ§Ã£o do ParÃ¢metro a (DiscriminaÃ§Ã£o)",
                                                   color='Ã‰ Ã‚ncora')
                                st.plotly_chart(fig_a, use_container_width=True)
                            
                            with col2:
                                fig_b = px.histogram(df_params, x='b (Dificuldade)', nbins=15,
                                                   title="DistribuiÃ§Ã£o do ParÃ¢metro b (Dificuldade)",
                                                   color='Ã‰ Ã‚ncora')
                                st.plotly_chart(fig_b, use_container_width=True)
                            
                            col3, col4 = st.columns(2)
                            
                            with col3:
                                fig_c = px.histogram(df_params, x='c (Acerto ao acaso)', nbins=15,
                                                   title="DistribuiÃ§Ã£o do ParÃ¢metro c (Acerto ao acaso)",
                                                   color='Ã‰ Ã‚ncora')
                                st.plotly_chart(fig_c, use_container_width=True)
                            
                            with col4:
                                # Scatter plot a vs b com cores para Ã¢ncora
                                fig_scatter = px.scatter(df_params, x='b (Dificuldade)', y='a (DiscriminaÃ§Ã£o)',
                                                       title="CorrelaÃ§Ã£o: Dificuldade vs DiscriminaÃ§Ã£o",
                                                       color='Ã‰ Ã‚ncora',
                                                       hover_data=['QuestÃ£o'])
                                st.plotly_chart(fig_scatter, use_container_width=True)
                            
                            # BotÃ£o de download
                            csv_data = df_params.to_csv(index=False)
                            st.download_button(
                                label="ğŸ“¥ Download ParÃ¢metros Calibrados",
                                data=csv_data,
                                file_name=f"parametros_calibrados_{param_set.id}.csv",
                                mime="text/csv",
                                key=f"download_calibrated_{param_set.id}"
                            )
            else:
                st.info("â„¹ï¸ Nenhum parÃ¢metro calibrado encontrado.")
        
        # Resumo geral
        if params_sets:
            st.subheader("ğŸ“Š Resumo Geral dos ParÃ¢metros")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Total de Conjuntos", len(params_sets))
            
            with col2:
                st.metric("Conjuntos Ã‚ncora", len(anchor_params))
            
            with col3:
                st.metric("Conjuntos Calibrados", len(calibrated_params))
            
            with col4:
                total_items = sum(len(ParametersSetCRUD.get_item_parameters(session, p.id)) for p in params_sets)
                st.metric("Total de Itens", total_items)

def main():
    """FunÃ§Ã£o principal"""
    try:
        # Verificar autenticaÃ§Ã£o
        require_authentication()
        
        # Header
        st.title("ğŸ“Š Sistema TRI Profissional v2")
        st.markdown("---")
        
        # Sidebar simples
        with st.sidebar:
            st.title("ğŸ§­ NavegaÃ§Ã£o")
            
            if st.button("ğŸ  Dashboard", key="nav_dashboard", width='stretch'):
                st.session_state['current_page'] = 'dashboard'
                st.rerun()
            
            if st.button("ğŸ“‹ AvaliaÃ§Ãµes", key="nav_assessments", width='stretch'):
                st.session_state['current_page'] = 'assessments'
                st.rerun()
            
            if st.button("âš™ï¸ ExecuÃ§Ãµes", key="nav_executions", width='stretch'):
                st.session_state['current_page'] = 'executions'
                st.rerun()
            
            st.markdown("---")
            
            # InformaÃ§Ãµes do usuÃ¡rio
            user_info = st.session_state.get('user_name', 'UsuÃ¡rio')
            st.info(f"ğŸ‘¤ **{user_info}**")
            
            # BotÃ£o de logout na sidebar
            if st.button("ğŸšª Sair", width='stretch', key="btn_logout_sidebar"):
                from auth.authentication import AuthenticationManager
                AuthenticationManager().logout_user()
                st.rerun()
        
        # ConteÃºdo principal
        page = st.session_state.get('current_page', 'dashboard')
        
        if page == 'dashboard':
            st.subheader("ğŸ  Dashboard Principal")
            st.success("âœ… Dashboard funcionando!")
            
            # MÃ©tricas reais
            try:
                with get_db_session_context() as session:
                    assessments = AssessmentCRUD.list_assessments(session)
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("AvaliaÃ§Ãµes", len(assessments))
                    with col2:
                        st.metric("ExecuÃ§Ãµes", "0")  # Implementar depois
                    with col3:
                        st.metric("Estudantes", "0")  # Implementar depois
                    
                    # Mostrar avaliaÃ§Ãµes recentes
                    if assessments:
                        st.subheader("ğŸ“‹ AvaliaÃ§Ãµes Recentes")
                        for assessment in assessments[:3]:  # Mostrar apenas as 3 mais recentes
                            st.info(f"ğŸ¯ **{assessment.description or f'AvaliaÃ§Ã£o {assessment.year}'}** - {assessment.level} ({assessment.cicle})")
                    
            except Exception as e:
                logger.error(f"Erro ao carregar mÃ©tricas: {e}")
                st.error("Erro ao carregar mÃ©tricas")
        
        elif page == 'assessments':
            show_assessments_page()
        
        elif page == 'executions':
            show_executions_page()
        
    except Exception as e:
        st.error(f"âŒ Erro: {e}")
        logger.error(f"Erro no dashboard: {e}")

if __name__ == "__main__":
    main()
