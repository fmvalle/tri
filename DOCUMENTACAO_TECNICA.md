# üìä Documenta√ß√£o T√©cnica - Sistema TRI

## üéØ Vis√£o Geral

Este documento apresenta a implementa√ß√£o t√©cnica do Sistema TRI (Teoria de Resposta ao Item) baseado no modelo de 3 par√¢metros (3PL), seguindo as metodologias utilizadas no ENEM/SAEB. O sistema foi desenvolvido para estat√≠sticos e psicometristas que necessitam de uma ferramenta robusta para an√°lise de dados educacionais.

## üÜï **Atualiza√ß√µes Recentes (v2.0)**

### **Corre√ß√µes Implementadas:**
- ‚úÖ **Colunas duplicadas removidas**: Padroniza√ß√£o para `theta`, `enem_score`, `acertos`, `total_itens`, `percentual_acertos`
- ‚úÖ **Debug removido**: Interface limpa e profissional
- ‚úÖ **Erro DataValidator corrigido**: Valida√ß√£o funcionando corretamente
- ‚úÖ **Nova aba "Par√¢metros Salvos"**: Gerenciamento de itens calibrados
- ‚úÖ **Depend√™ncias atualizadas**: statsmodels inclu√≠do para funcionalidades avan√ßadas

### **Estrutura de Dados Padr√£o:**
```python
# Colunas padr√£o dos resultados:
- CodPessoa: Identificador √∫nico do estudante
- theta: Profici√™ncia latente estimada
- enem_score: Nota na escala ENEM
- acertos: N√∫mero de itens acertados
- total_itens: Total de itens do teste
- percentual_acertos: Percentual de acertos calculado
```

## üî¨ Modelo TRI Implementado

### **Modelo 3PL (Birnbaum, 1968)**

A fun√ß√£o de resposta ao item implementada segue o modelo de tr√™s par√¢metros:

```
P(Œ∏) = c + (1-c)/(1 + e^(-1.7*a*(Œ∏-b)))
```

Onde:
- **Œ∏ (theta)**: Profici√™ncia latente do respondente
- **a**: Par√¢metro de discrimina√ß√£o (a > 0)
- **b**: Par√¢metro de dificuldade (-‚àû < b < +‚àû)
- **c**: Par√¢metro de acerto casual (0 ‚â§ c ‚â§ 1)
- **1.7**: Constante de escala (aproxima√ß√£o de 1.702)

### **Interpreta√ß√£o dos Par√¢metros**

#### **Par√¢metro a (Discrimina√ß√£o)**
- **a > 1**: Item com alta discrimina√ß√£o
- **a ‚âà 1**: Discrimina√ß√£o moderada
- **a < 1**: Baixa discrimina√ß√£o
- **a ‚Üí 0**: Item n√£o discriminativo

#### **Par√¢metro b (Dificuldade)**
- **b > 0**: Item dif√≠cil (Œ∏ > b para P(Œ∏) > 0.5)
- **b = 0**: Dificuldade m√©dia
- **b < 0**: Item f√°cil

#### **Par√¢metro c (Acerto Casual)**
- **c = 0**: Sem acerto casual (modelo 2PL)
- **c > 0**: Probabilidade de acerto por chute
- **c ‚â§ 0.25**: Valores t√≠picos para testes de m√∫ltipla escolha

## üéØ Sistema de Itens √Çncora

### **Fundamenta√ß√£o Te√≥rica**

O sistema de itens √¢ncora implementa a metodologia de **equating** para manter a consist√™ncia da escala entre diferentes aplica√ß√µes de um teste. Esta abordagem √© fundamental para:

1. **Comparabilidade**: Resultados de diferentes aplica√ß√µes na mesma escala
2. **Valida√ß√£o**: Verifica√ß√£o da qualidade dos novos itens
3. **Efici√™ncia**: Redu√ß√£o do n√∫mero de itens a serem calibrados
4. **Padr√£o**: Seguir metodologias aceitas internacionalmente

## üìã **Gerenciamento de Par√¢metros Salvos**

### **Nova Funcionalidade: Aba "Par√¢metros Salvos"**

O sistema agora inclui uma interface dedicada para gerenciar os par√¢metros dos itens calibrados:

#### **Funcionalidades Principais:**
- **üìä Visualiza√ß√£o**: Lista todos os conjuntos de par√¢metros salvos
- **‚úèÔ∏è Renomea√ß√£o**: Permite personalizar nomes para identifica√ß√£o f√°cil
- **üì• Download CSV**: Exporta par√¢metros em formato CSV
- **üîç Estat√≠sticas**: Mostra m√©dias dos par√¢metros a, b, c
- **üéØ Identifica√ß√£o de √Çncoras**: Indica quais conjuntos s√£o itens √¢ncora

#### **Estrutura dos Par√¢metros:**
```python
# Colunas dos par√¢metros salvos:
- questao: N√∫mero da quest√£o
- a: Par√¢metro de discrimina√ß√£o
- b: Par√¢metro de dificuldade  
- c: Par√¢metro de acerto casual
- is_anchor: Indica se √© item √¢ncora
```

#### **Opera√ß√µes CRUD:**
```python
# Listar conjuntos de par√¢metros
parameters_sets = crud.list_parameters_sets(session)

# Obter par√¢metros espec√≠ficos
params_df = crud.get_parameters_set(session, parameters_set_id)

# Atualizar nome do conjunto
crud.update_parameters_set_name(session, parameters_set_id, new_name)
```

### **Implementa√ß√£o T√©cnica**

#### **1. Identifica√ß√£o de √Çncoras**

```python
def _identify_anchor_items(self, anchor_items: Dict, item_mapping: Dict) -> np.ndarray:
    """
    Cria m√°scara booleana para identificar itens √¢ncora
    """
    anchor_mask = np.zeros(len(item_mapping), dtype=bool)
    
    for questao, params in anchor_items.items():
        if questao in item_mapping:
            idx = item_mapping[questao] - 1
            anchor_mask[idx] = True
    
    return anchor_mask
```

#### **2. Calibra√ß√£o Relativa**

Os itens n√£o-√¢ncora s√£o calibrados usando os √¢ncoras como refer√™ncia:

```python
def _calibrate_non_anchor_items(self, response_array: np.ndarray, 
                               anchor_mask: np.ndarray,
                               anchor_items: Optional[Dict],
                               item_mapping: Dict) -> pd.DataFrame:
    """
    Calibra itens n√£o ancorados usando otimiza√ß√£o
    """
    calibrated_params = []
    
    for item_idx in range(response_array.shape[1]):
        if not anchor_mask[item_idx]:
            # Item n√£o ancorado - calibrar
            questao = list(item_mapping.keys())[item_idx]
            item_responses = response_array[:, item_idx]
            
            # Remover respostas nulas
            valid_mask = ~np.isnan(item_responses)
            if np.sum(valid_mask) < 10:  # M√≠nimo de respostas v√°lidas
                params = {'a': 1.0, 'b': 0.0, 'c': 0.2}
            else:
                params = self._estimate_item_parameters(item_responses[valid_mask])
            
            calibrated_params.append({
                'Questao': questao,
                'a': params['a'],
                'b': params['b'],
                'c': params['c'],
                'calibrated': True
            })
    
    return pd.DataFrame(calibrated_params)
```

#### **3. Estima√ß√£o de Par√¢metros**

A estima√ß√£o utiliza m√°xima verossimilhan√ßa com restri√ß√µes:

```python
def _estimate_item_parameters(self, responses: np.ndarray) -> Dict:
    """
    Estima par√¢metros usando m√°xima verossimilhan√ßa
    """
    # Valores iniciais
    initial_params = [1.0, 0.0, 0.2]  # a, b, c
    
    # Fun√ß√£o objetivo: log-likelihood
    def objective(params):
        a, b, c = params
        if a <= 0 or c < 0 or c > 1:
            return 1e6  # Penalidade para par√¢metros inv√°lidos
        
        # Calcular probabilidades esperadas
        theta_est = np.mean(responses)  # Estimativa simples de theta
        p_correct = c + (1 - c) / (1 + np.exp(-1.7 * a * (theta_est - b)))
        
        # Log-likelihood
        ll = np.sum(responses * np.log(p_correct) + 
                   (1 - responses) * np.log(1 - p_correct))
        return -ll  # Minimizar -log-likelihood
    
    # Otimiza√ß√£o com restri√ß√µes
    try:
        result = minimize(objective, initial_params, method='L-BFGS-B',
                        bounds=[(0.1, 5.0), (-3.0, 3.0), (0.0, 0.5)])
        
        if result.success:
            return {'a': result.x[0], 'b': result.x[1], 'c': result.x[2]}
        else:
            return {'a': 1.0, 'b': 0.0, 'c': 0.2}
            
    except Exception:
        return {'a': 1.0, 'b': 0.0, 'c': 0.2}
```

### **Valida√ß√£o de √Çncoras**

#### **Crit√©rios de Qualidade**

1. **N√∫mero m√≠nimo**: Pelo menos 5 itens √¢ncora por dom√≠nio
2. **Distribui√ß√£o**: Cobertura adequada da escala de dificuldade
3. **Discrimina√ß√£o**: Itens com a ‚â• 0.5
4. **Estabilidade**: Par√¢metros bem estimados (erro padr√£o < 0.1)

#### **Implementa√ß√£o da Valida√ß√£o**

```python
def validate_calibration(self, params_df: pd.DataFrame) -> Dict:
    """
    Valida par√¢metros calibrados
    """
    validation = {
        'valid': True,
        'warnings': [],
        'errors': []
    }
    
    # Verificar valores dos par√¢metros
    if (params_df['a'] <= 0).any():
        validation['errors'].append("Par√¢metros 'a' devem ser positivos")
        validation['valid'] = False
    
    if (params_df['c'] < 0).any() or (params_df['c'] > 1).any():
        validation['errors'].append("Par√¢metros 'c' devem estar entre 0 e 1")
        validation['valid'] = False
    
    # Verificar valores extremos
    if (params_df['a'] > 10).any():
        validation['warnings'].append("Alguns par√¢metros 'a' s√£o muito altos")
    
    if (params_df['b'] < -5).any() or (params_df['b'] > 5).any():
        validation['warnings'].append("Alguns par√¢metros 'b' s√£o extremos")
    
    return validation
```

## üìä Estima√ß√£o de Theta

### **Algoritmo de M√°xima Verossimilhan√ßa**

#### **Fun√ß√£o de Verossimilhan√ßa**

```
L(Œ∏) = ‚àè·µ¢ P·µ¢(Œ∏) ∏‚Å± √ó [1 - P·µ¢(Œ∏)]^(1- ∏‚Å±)
```

Onde:
- **L(Œ∏)**: Verossimilhan√ßa da profici√™ncia Œ∏
- **P·µ¢(Œ∏)**: Probabilidade de acerto no item i
- ** ∏‚Å±**: Resposta observada (0 ou 1)

#### **Implementa√ß√£o**

```python
def estimate_theta(self, responses: np.ndarray, a_params: np.ndarray, 
                  b_params: np.ndarray, c_params: np.ndarray) -> float:
    """
    Estima a profici√™ncia (theta) de um aluno
    """
    bounds = self.config["theta_bounds"]
    
    # Otimiza√ß√£o com diferentes pontos iniciais para evitar m√≠nimos locais
    initial_points = [-2.0, -1.0, 0.0, 1.0, 2.0]
    best_theta = 0.0
    best_ll = float('inf')
    
    for initial_theta in initial_points:
        try:
            result = minimize_scalar(
                lambda theta: self.log_likelihood(theta, responses, a_params, b_params, c_params),
                bounds=bounds,
                method='bounded',
                options={'xatol': 1e-6}
            )
            
            if result.success and result.fun < best_ll:
                best_theta = result.x
                best_ll = result.fun
                
        except Exception:
            continue
    
    return best_theta
```

### **Tratamento de Respostas Extremas**

#### **Respostas Perfeitas (All Correct)**
- **Problema**: Log-likelihood tende a +‚àû
- **Solu√ß√£o**: Estimativa de theta = limite superior da escala

#### **Respostas Nulas (All Wrong)**
- **Problema**: Log-likelihood tende a +‚àû
- **Solu√ß√£o**: Estimativa de theta = limite inferior da escala

#### **Implementa√ß√£o**

```python
def _handle_extreme_responses(self, responses: np.ndarray, 
                             a_params: np.ndarray, b_params: np.ndarray, 
                             c_params: np.ndarray) -> float:
    """
    Trata respostas extremas (todas corretas ou todas incorretas)
    """
    if np.all(responses == 1):
        return self.config["theta_bounds"][1]  # Limite superior
    elif np.all(responses == 0):
        return self.config["theta_bounds"][0]  # Limite inferior
    else:
        return None  # Resposta normal, usar estima√ß√£o
```

## üîç Valida√ß√£o e Qualidade dos Dados

### **Crit√©rios de Valida√ß√£o**

#### **1. Dados de Entrada**
- **Completude**: M√≠nimo 90% de respostas v√°lidas
- **Consist√™ncia**: Respostas bin√°rias (0/1)
- **Tamanho**: M√≠nimo 10 estudantes, m√°ximo 100.000

#### **2. Par√¢metros dos Itens**
- **a**: 0.1 ‚â§ a ‚â§ 10.0
- **b**: -5.0 ‚â§ b ‚â§ 5.0
- **c**: 0.0 ‚â§ c ‚â§ 0.5

#### **3. Resultados**
- **Theta**: -4.0 ‚â§ Œ∏ ‚â§ 4.0
- **Nota ENEM**: 100 ‚â§ nota ‚â§ 900

### **Implementa√ß√£o da Valida√ß√£o**

```python
def validate_data_quality(self, df: pd.DataFrame) -> bool:
    """
    Valida qualidade dos dados de entrada
    """
    # Verificar colunas obrigat√≥rias
    required_cols = ["CodPessoa", "Questao", "RespostaAluno", "Gabarito"]
    if not all(col in df.columns for col in required_cols):
        return False
    
    # Verificar tamanho m√≠nimo
    if len(df) < 50:  # M√≠nimo de respostas
        return False
    
    # Verificar completude
    completeness = 1 - df.isnull().sum().sum() / (len(df) * len(df.columns))
    if completeness < 0.9:
        return False
    
    return True
```

## üìà Escala e Normaliza√ß√£o

### **Convers√£o para Escala ENEM**

#### **F√≥rmula de Convers√£o**

```
Nota ENEM = 500 + 100 √ó Œ∏
```

Onde:
- **500**: Nota base (m√©dia da escala)
- **100**: Fator de escala
- **Œ∏**: Theta estimado na escala log√≠stica

#### **Implementa√ß√£o**

```python
def convert_to_enem_scale(self, theta: float) -> float:
    """
    Converte theta para escala ENEM
    """
    enem_base = self.config["enem_base"]
    enem_scale = self.config["enem_scale"]
    
    nota = enem_base + enem_scale * theta
    return np.clip(nota, 100, 900)  # Limites da escala ENEM
```

### **Normaliza√ß√£o dos Par√¢metros**

#### **Padroniza√ß√£o dos Par√¢metros b**

Para facilitar interpreta√ß√£o, os par√¢metros b podem ser normalizados:

```python
def normalize_b_parameters(self, b_params: np.ndarray) -> np.ndarray:
    """
    Normaliza par√¢metros b para m√©dia 0 e desvio padr√£o 1
    """
    mean_b = np.mean(b_params)
    std_b = np.std(b_params)
    
    if std_b > 0:
        normalized_b = (b_params - mean_b) / std_b
    else:
        normalized_b = b_params - mean_b
    
    return normalized_b
```

## üßÆ Otimiza√ß√µes Num√©ricas

### **Algoritmos de Otimiza√ß√£o**

#### **1. L-BFGS-B para Par√¢metros dos Itens**
- **Vantagem**: Eficiente para problemas com restri√ß√µes
- **Aplica√ß√£o**: Calibra√ß√£o de par√¢metros a, b, c
- **Configura√ß√£o**: Bounds espec√≠ficos para cada par√¢metro

#### **2. Brent para Estima√ß√£o de Theta**
- **Vantagem**: Est√°vel para fun√ß√µes unidimensionais
- **Aplica√ß√£o**: Estima√ß√£o de profici√™ncia individual
- **Configura√ß√£o**: Limites [-4, 4] para evitar valores extremos

### **Tratamento de Problemas Num√©ricos**

#### **1. Evitar Overflow/Underflow**
```python
def safe_log(self, x: float) -> float:
    """
    Logaritmo seguro para evitar problemas num√©ricos
    """
    return np.log(np.clip(x, 1e-10, 1 - 1e-10))
```

#### **2. M√∫ltiplos Pontos Iniciais**
```python
def estimate_theta_robust(self, responses: np.ndarray, 
                         a_params: np.ndarray, b_params: np.ndarray, 
                         c_params: np.ndarray) -> float:
    """
    Estima√ß√£o robusta de theta com m√∫ltiplos pontos iniciais
    """
    initial_points = [-3.0, -1.5, 0.0, 1.5, 3.0]
    best_theta = 0.0
    best_ll = float('inf')
    
    for initial_theta in initial_points:
        try:
            result = minimize_scalar(
                lambda theta: self.log_likelihood(theta, responses, a_params, b_params, c_params),
                bounds=(-4, 4),
                method='bounded'
            )
            
            if result.success and result.fun < best_ll:
                best_theta = result.x
                best_ll = result.fun
                
        except Exception:
            continue
    
    return best_theta
```

## üìä An√°lise de Qualidade dos Itens

### **√çndices de Qualidade**

#### **1. √çndice de Discrimina√ß√£o (a)**
- **Excelente**: a > 1.0
- **Bom**: 0.5 ‚â§ a ‚â§ 1.0
- **Regular**: 0.3 ‚â§ a < 0.5
- **Ruim**: a < 0.3

#### **2. √çndice de Dificuldade (b)**
- **Muito f√°cil**: b < -1.5
- **F√°cil**: -1.5 ‚â§ b < -0.5
- **M√©dio**: -0.5 ‚â§ b ‚â§ 0.5
- **Dif√≠cil**: 0.5 < b ‚â§ 1.5
- **Muito dif√≠cil**: b > 1.5

#### **3. √çndice de Acerto Casual (c)**
- **Aceit√°vel**: c ‚â§ 0.25
- **Alto**: 0.25 < c ‚â§ 0.35
- **Muito alto**: c > 0.35

### **Implementa√ß√£o dos √çndices**

```python
def calculate_item_quality_indices(self, params_df: pd.DataFrame) -> pd.DataFrame:
    """
    Calcula √≠ndices de qualidade dos itens
    """
    quality_df = params_df.copy()
    
    # √çndice de discrimina√ß√£o
    quality_df['discrimination_quality'] = quality_df['a'].apply(
        lambda x: 'Excelente' if x > 1.0 else
                  'Bom' if x >= 0.5 else
                  'Regular' if x >= 0.3 else 'Ruim'
    )
    
    # √çndice de dificuldade
    quality_df['difficulty_quality'] = quality_df['b'].apply(
        lambda x: 'Muito f√°cil' if x < -1.5 else
                  'F√°cil' if x < -0.5 else
                  'M√©dio' if x <= 0.5 else
                  'Dif√≠cil' if x <= 1.5 else 'Muito dif√≠cil'
    )
    
    # √çndice de acerto casual
    quality_df['guessing_quality'] = quality_df['c'].apply(
        lambda x: 'Aceit√°vel' if x <= 0.25 else
                  'Alto' if x <= 0.35 else 'Muito alto'
    )
    
    return quality_df
```

## üî¨ Testes e Valida√ß√£o

### **Testes de Consist√™ncia**

#### **1. Teste de Ajuste do Modelo**
- **Chi-quadrado**: Compara√ß√£o entre frequ√™ncias observadas e esperadas
- **Implementa√ß√£o**: Agrupamento de respostas por faixas de theta

#### **2. An√°lise de Res√≠duos**
- **Res√≠duos padronizados**: Diferen√ßa entre observado e esperado
- **Crit√©rio**: |res√≠duo| < 2.0 para 95% dos casos

#### **3. Teste de Independ√™ncia Local**
- **Hip√≥tese**: Respostas independentes condicionadas ao theta
- **M√©todo**: Correla√ß√£o entre res√≠duos de itens diferentes

### **Implementa√ß√£o dos Testes**

```python
def test_model_fit(self, responses: np.ndarray, thetas: np.ndarray,
                   a_params: np.ndarray, b_params: np.ndarray, 
                   c_params: np.ndarray) -> Dict:
    """
    Testa o ajuste do modelo 3PL
    """
    # Agrupar por faixas de theta
    theta_bins = pd.cut(thetas, bins=5, labels=False)
    
    chi_square_stats = []
    for bin_idx in range(5):
        bin_mask = theta_bins == bin_idx
        if np.sum(bin_mask) > 0:
            bin_responses = responses[bin_mask]
            bin_thetas = thetas[bin_mask]
            
            # Calcular frequ√™ncias esperadas
            expected_probs = np.array([
                self.prob_3pl(theta, a, b, c)
                for theta, a, b, c in zip(bin_thetas, a_params, b_params, c_params)
            ])
            
            # Chi-quadrado
            observed = bin_responses
            expected = expected_probs
            chi_square = np.sum((observed - expected) ** 2 / expected)
            chi_square_stats.append(chi_square)
    
    # Estat√≠stica total
    total_chi_square = np.sum(chi_square_stats)
    df = len(chi_square_stats) - 1
    
    return {
        'chi_square': total_chi_square,
        'degrees_of_freedom': df,
        'p_value': 1 - chi2.cdf(total_chi_square, df),
        'significant': total_chi_square > chi2.ppf(0.95, df)
    }
```

## üìà Relat√≥rios e Visualiza√ß√µes

### **Relat√≥rios Autom√°ticos**

#### **1. Relat√≥rio de Calibra√ß√£o**
- Par√¢metros estimados com erros padr√£o
- √çndices de qualidade dos itens
- Gr√°ficos de informa√ß√£o dos itens
- Testes de ajuste do modelo

#### **2. Relat√≥rio de Aplica√ß√£o**
- Estat√≠sticas descritivas das profici√™ncias
- Distribui√ß√£o das notas ENEM
- An√°lise de consist√™ncia interna
- Compara√ß√£o com normas de refer√™ncia

### **Gr√°ficos Espec√≠ficos**

#### **1. Curva Caracter√≠stica do Item (CCI)**
```python
def plot_item_characteristic_curve(self, a: float, b: float, c: float, 
                                 theta_range: np.ndarray) -> go.Figure:
    """
    Plota a curva caracter√≠stica do item
    """
    probs = [self.prob_3pl(theta, a, b, c) for theta in theta_range]
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=theta_range,
        y=probs,
        mode='lines',
        name=f'Item (a={a:.2f}, b={b:.2f}, c={c:.2f})'
    ))
    
    fig.update_layout(
        title='Curva Caracter√≠stica do Item',
        xaxis_title='Theta (Profici√™ncia)',
        yaxis_title='Probabilidade de Acerto',
        xaxis=dict(range=[-4, 4]),
        yaxis=dict(range=[0, 1])
    )
    
    return fig
```

#### **2. Fun√ß√£o de Informa√ß√£o do Item**
```python
def plot_item_information_function(self, a: float, b: float, c: float,
                                 theta_range: np.ndarray) -> go.Figure:
    """
    Plota a fun√ß√£o de informa√ß√£o do item
    """
    info_values = []
    for theta in theta_range:
        p = self.prob_3pl(theta, a, b, c)
        info = (a ** 2) * p * (1 - p) * ((1 - c) ** 2) / ((p - c) ** 2)
        info_values.append(info)
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=theta_range,
        y=info_values,
        mode='lines',
        name=f'Informa√ß√£o (a={a:.2f}, b={b:.2f}, c={c:.2f})'
    ))
    
    fig.update_layout(
        title='Fun√ß√£o de Informa√ß√£o do Item',
        xaxis_title='Theta (Profici√™ncia)',
        yaxis_title='Informa√ß√£o',
        xaxis=dict(range=[-4, 4])
    )
    
    return fig
```

## üöÄ Considera√ß√µes para Produ√ß√£o

### **Performance e Escalabilidade**

#### **1. Otimiza√ß√µes de Mem√≥ria**
- Processamento em lotes para grandes datasets
- Uso de arrays NumPy em vez de listas Python
- Limpeza autom√°tica de vari√°veis intermedi√°rias

#### **2. Paraleliza√ß√£o**
- Processamento paralelo de m√∫ltiplos alunos
- Uso de multiprocessing para calibra√ß√£o de itens
- Distribui√ß√£o de carga em m√∫ltiplos cores

#### **3. Cache e Persist√™ncia**
- Cache de par√¢metros calibrados
- Persist√™ncia de resultados intermedi√°rios
- Recupera√ß√£o de falhas de processamento

### **Monitoramento e Logging**

#### **1. M√©tricas de Performance**
- Tempo de processamento por item
- Uso de mem√≥ria durante calibra√ß√£o
- Taxa de converg√™ncia dos algoritmos

#### **2. Alertas de Qualidade**
- Par√¢metros fora dos limites aceit√°veis
- Falhas de converg√™ncia na otimiza√ß√£o
- Inconsist√™ncias nos dados de entrada

## üìö Refer√™ncias Bibliogr√°ficas

1. **Birnbaum, A. (1968)**. Some latent trait models and their use in inferring an examinee's ability. In F. M. Lord & M. R. Novick (Eds.), *Statistical theories of mental test scores* (pp. 397-479). Reading, MA: Addison-Wesley.

2. **Baker, F. B., & Kim, S. H. (2017)**. *The basics of item response theory using R*. New York: Springer.

3. **De Ayala, R. J. (2009)**. *The theory and practice of item response theory*. New York: The Guilford Press.

4. **Hambleton, R. K., Swaminathan, H., & Rogers, H. J. (1991)**. *Fundamentals of item response theory*. Newbury Park, CA: Sage.

5. **Lord, F. M. (1980)**. *Applications of item response theory to practical testing problems*. Hillsdale, NJ: Lawrence Erlbaum Associates.

## üîó Links √öteis

- **Documenta√ß√£o oficial**: [Link para documenta√ß√£o]
- **Reposit√≥rio GitHub**: [Link para reposit√≥rio]
- **Issues e suporte**: [Link para issues]
- **Wiki do projeto**: [Link para wiki]

---

**Desenvolvido para a comunidade cient√≠fica e educacional**

*√öltima atualiza√ß√£o: Dezembro 2024*
