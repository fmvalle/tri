# üìä Documenta√ß√£o T√©cnica - Sistema TRI

## üéØ Vis√£o Geral

Este documento apresenta a implementa√ß√£o t√©cnica do Sistema TRI (Teoria de Resposta ao Item) baseado no modelo de 3 par√¢metros (3PL), seguindo as metodologias utilizadas no ENEM/SAEB. O sistema foi desenvolvido para estat√≠sticos e psicometristas que necessitam de uma ferramenta robusta para an√°lise de dados educacionais.

## üÜï **Atualiza√ß√µes Recentes (v3.0)**

### **Corre√ß√µes Implementadas:**
- ‚úÖ **Colunas duplicadas removidas**: Padroniza√ß√£o para `theta`, `enem_score`, `acertos`, `total_itens`, `percentual_acertos`
- ‚úÖ **Debug removido**: Interface limpa e profissional
- ‚úÖ **Erro DataValidator corrigido**: Valida√ß√£o funcionando corretamente
- ‚úÖ **Nova aba "Par√¢metros Salvos"**: Gerenciamento de itens calibrados
- ‚úÖ **Depend√™ncias atualizadas**: statsmodels inclu√≠do para funcionalidades avan√ßadas
- ‚úÖ **Problema "theta travado" corrigido**: Algoritmo de calibra√ß√£o otimizado
- ‚úÖ **Escala theta expandida**: De (-4,4) para (-5,5) - 5 desvios padr√£o
- ‚úÖ **Convers√£o ENEM corrigida**: Sem limite m√°ximo, apenas m√≠nimo 0
- ‚úÖ **Interface reorganizada**: Sub-abas no Processamento TRI
- ‚úÖ **Percentual de acertos**: Nova coluna nos resultados
- ‚úÖ **IDs duplicados corrigidos**: Chaves √∫nicas para todos os elementos Streamlit

### **Estrutura de Dados Padr√£o:**
```python
# Colunas padr√£o dos resultados:
- CodPessoa: Identificador √∫nico do estudante
- theta: Profici√™ncia latente estimada (escala -5 a +5)
- enem_score: Nota na escala ENEM (sem limite m√°ximo)
- acertos: N√∫mero de itens acertados
- total_itens: Total de itens do teste
- percentual_acertos: Percentual de acertos calculado (%)
```

### **Melhorias na Calibra√ß√£o:**
- ‚úÖ **Estimativa robusta de theta**: Baseada na propor√ß√£o observada de acertos
- ‚úÖ **M√∫ltiplos pontos iniciais**: Evita m√≠nimos locais na otimiza√ß√£o
- ‚úÖ **Constante 1.7 inclu√≠da**: F√≥rmula 3PL matematicamente correta
- ‚úÖ **Tratamento de casos extremos**: Respostas perfeitas e nulas

## üî¨ Modelo TRI Implementado

### **Modelo 3PL (Birnbaum, 1968)**

A fun√ß√£o de resposta ao item implementada segue o modelo de tr√™s par√¢metros:

```
P(Œ∏) = c + (1-c)/(1 + e^(-1.7*a*(Œ∏-b)))
```

Onde:
- **Œ∏ (theta)**: Profici√™ncia latente do respondente
- **a**: Par√¢metro de discrimina√ß√£o (a > 0)
- **b**: Par√¢metro de dificuldade (-‚àû < b < +‚àû)
- **c**: Par√¢metro de acerto casual (0 ‚â§ c ‚â§ 1)
- **1.7**: Constante de escala (aproxima√ß√£o de 1.702)

### **Interpreta√ß√£o dos Par√¢metros**

#### **Par√¢metro a (Discrimina√ß√£o)**
- **a > 1**: Item com alta discrimina√ß√£o
- **a ‚âà 1**: Discrimina√ß√£o moderada
- **a < 1**: Baixa discrimina√ß√£o
- **a ‚Üí 0**: Item n√£o discriminativo

#### **Par√¢metro b (Dificuldade)**
- **b > 0**: Item dif√≠cil (Œ∏ > b para P(Œ∏) > 0.5)
- **b = 0**: Dificuldade m√©dia
- **b < 0**: Item f√°cil

#### **Par√¢metro c (Acerto Casual)**
- **c = 0**: Sem acerto casual (modelo 2PL)
- **c > 0**: Probabilidade de acerto por chute
- **c ‚â§ 0.25**: Valores t√≠picos para testes de m√∫ltipla escolha

## üéØ Sistema de Itens √Çncora

### **Fundamenta√ß√£o Te√≥rica**

O sistema de itens √¢ncora implementa a metodologia de **equating** para manter a consist√™ncia da escala entre diferentes aplica√ß√µes de um teste. Esta abordagem √© fundamental para:

1. **Comparabilidade**: Resultados de diferentes aplica√ß√µes na mesma escala
2. **Valida√ß√£o**: Verifica√ß√£o da qualidade dos novos itens
3. **Efici√™ncia**: Redu√ß√£o do n√∫mero de itens a serem calibrados
4. **Padr√£o**: Seguir metodologias aceitas internacionalmente

## üìã **Gerenciamento de Par√¢metros Salvos**

### **Nova Funcionalidade: Aba "Par√¢metros Salvos"**

O sistema agora inclui uma interface dedicada para gerenciar os par√¢metros dos itens calibrados:

#### **Funcionalidades Principais:**
- **üìä Visualiza√ß√£o**: Lista todos os conjuntos de par√¢metros salvos
- **‚úèÔ∏è Renomea√ß√£o**: Permite personalizar nomes para identifica√ß√£o f√°cil
- **üì• Download CSV**: Exporta par√¢metros em formato CSV
- **üîç Estat√≠sticas**: Mostra m√©dias dos par√¢metros a, b, c
- **üéØ Identifica√ß√£o de √Çncoras**: Indica quais conjuntos s√£o itens √¢ncora

#### **Estrutura dos Par√¢metros:**
```python
# Colunas dos par√¢metros salvos:
- questao: N√∫mero da quest√£o
- a: Par√¢metro de discrimina√ß√£o
- b: Par√¢metro de dificuldade  
- c: Par√¢metro de acerto casual
- is_anchor: Indica se √© item √¢ncora
```

#### **Opera√ß√µes CRUD:**
```python
# Listar conjuntos de par√¢metros
parameters_sets = crud.list_parameters_sets(session)

# Obter par√¢metros espec√≠ficos
params_df = crud.get_parameters_set(session, parameters_set_id)

# Atualizar nome do conjunto
crud.update_parameters_set_name(session, parameters_set_id, new_name)
```

### **Implementa√ß√£o T√©cnica**

#### **1. Identifica√ß√£o de √Çncoras**

```python
def _identify_anchor_items(self, anchor_items: Dict, item_mapping: Dict) -> np.ndarray:
    """
    Cria m√°scara booleana para identificar itens √¢ncora
    """
    anchor_mask = np.zeros(len(item_mapping), dtype=bool)
    
    for questao, params in anchor_items.items():
        if questao in item_mapping:
            idx = item_mapping[questao] - 1
            anchor_mask[idx] = True
    
    return anchor_mask
```

#### **2. Calibra√ß√£o Relativa**

Os itens n√£o-√¢ncora s√£o calibrados usando os √¢ncoras como refer√™ncia:

```python
def _calibrate_non_anchor_items(self, response_array: np.ndarray, 
                               anchor_mask: np.ndarray,
                               anchor_items: Optional[Dict],
                               item_mapping: Dict) -> pd.DataFrame:
    """
    Calibra itens n√£o ancorados usando otimiza√ß√£o
    """
    calibrated_params = []
    
    for item_idx in range(response_array.shape[1]):
        if not anchor_mask[item_idx]:
            # Item n√£o ancorado - calibrar
            questao = list(item_mapping.keys())[item_idx]
            item_responses = response_array[:, item_idx]
            
            # Remover respostas nulas
            valid_mask = ~np.isnan(item_responses)
            if np.sum(valid_mask) < 10:  # M√≠nimo de respostas v√°lidas
                params = {'a': 1.0, 'b': 0.0, 'c': 0.2}
            else:
                params = self._estimate_item_parameters(item_responses[valid_mask])
            
            calibrated_params.append({
                'Questao': questao,
                'a': params['a'],
                'b': params['b'],
                'c': params['c'],
                'calibrated': True
            })
    
    return pd.DataFrame(calibrated_params)
```

#### **3. Estima√ß√£o de Par√¢metros**

A estima√ß√£o utiliza m√°xima verossimilhan√ßa com restri√ß√µes:

```python
def _estimate_item_parameters(self, responses: np.ndarray) -> Dict:
    """
    Estima par√¢metros de um item usando otimiza√ß√£o CORRIGIDA
    """
    # Valores iniciais
    initial_params = [1.0, 0.0, 0.2]  # a, b, c

    # Fun√ß√£o objetivo corrigida
    def objective(params):
        a, b, c = params
        if a <= 0 or c < 0 or c > 1:
            return 1e6  # Penalidade para par√¢metros inv√°lidos

        # CORRE√á√ÉO: Usar estimativa mais robusta de theta
        p_observed = np.mean(responses)

        # Estimativa inicial de theta baseada na propor√ß√£o observada
        if p_observed > c and p_observed < 1.0:
            theta_est = b + (1 / (1.7 * a)) * np.log((p_observed - c) / (1 - c))
        else:
            theta_est = 2 * (p_observed - 0.5)  # Mapear [0,1] para [-1,1]

        # CORRE√á√ÉO: Incluir constante 1.7 do modelo 3PL
        p_correct = c + (1 - c) / (1 + np.exp(-1.7 * a * (theta_est - b)))

        # Evitar problemas num√©ricos
        p_correct = np.clip(p_correct, 1e-6, 1 - 1e-6)

        # Log-likelihood
        ll = np.sum(responses * np.log(p_correct) + (1 - responses) * np.log(1 - p_correct))
        return -ll  # Minimizar -log-likelihood

    # Otimiza√ß√£o com m√∫ltiplos pontos iniciais
    best_params = None
    best_value = float('inf')

    # Diferentes pontos iniciais para evitar m√≠nimos locais
    initial_points = [
        [1.0, 0.0, 0.2],   # Padr√£o
        [0.8, -0.5, 0.15], # Alternativo 1
        [1.2, 0.5, 0.25],  # Alternativo 2
        [0.6, -1.0, 0.1],  # Alternativo 3
        [1.5, 1.0, 0.3],   # Alternativo 4
    ]

    for initial_point in initial_points:
        try:
            result = minimize(objective, initial_point, method='L-BFGS-B',
                            bounds=[(0.1, 5.0), (-3.0, 3.0), (0.0, 0.5)])

            if result.success and result.fun < best_value:
                best_params = result.x
                best_value = result.fun

        except Exception as e:
            self.logger.warning(f"Falha na otimiza√ß√£o com ponto inicial {initial_point}: {e}")
            continue

    if best_params is not None:
        return {'a': best_params[0], 'b': best_params[1], 'c': best_params[2]}
    else:
        self.logger.warning("Todas as otimiza√ß√µes falharam, usando valores padr√£o")
        return {'a': 1.0, 'b': 0.0, 'c': 0.2}
```

### **Valida√ß√£o de √Çncoras**

#### **Crit√©rios de Qualidade**

1. **N√∫mero m√≠nimo**: Pelo menos 5 itens √¢ncora por dom√≠nio
2. **Distribui√ß√£o**: Cobertura adequada da escala de dificuldade
3. **Discrimina√ß√£o**: Itens com a ‚â• 0.5
4. **Estabilidade**: Par√¢metros bem estimados (erro padr√£o < 0.1)

#### **Implementa√ß√£o da Valida√ß√£o**

```python
def validate_calibration(self, params_df: pd.DataFrame) -> Dict:
    """
    Valida par√¢metros calibrados
    """
    validation = {
        'valid': True,
        'warnings': [],
        'errors': []
    }
    
    # Verificar valores dos par√¢metros
    if (params_df['a'] <= 0).any():
        validation['errors'].append("Par√¢metros 'a' devem ser positivos")
        validation['valid'] = False
    
    if (params_df['c'] < 0).any() or (params_df['c'] > 1).any():
        validation['errors'].append("Par√¢metros 'c' devem estar entre 0 e 1")
        validation['valid'] = False
    
    # Verificar valores extremos
    if (params_df['a'] > 10).any():
        validation['warnings'].append("Alguns par√¢metros 'a' s√£o muito altos")
    
    if (params_df['b'] < -5).any() or (params_df['b'] > 5).any():
        validation['warnings'].append("Alguns par√¢metros 'b' s√£o extremos")
    
    return validation
```

## üìä Estima√ß√£o de Theta

### **Algoritmo de M√°xima Verossimilhan√ßa**

#### **Fun√ß√£o de Verossimilhan√ßa**

```
L(Œ∏) = ‚àè·µ¢ P·µ¢(Œ∏) ∏‚Å± √ó [1 - P·µ¢(Œ∏)]^(1- ∏‚Å±)
```

Onde:
- **L(Œ∏)**: Verossimilhan√ßa da profici√™ncia Œ∏
- **P·µ¢(Œ∏)**: Probabilidade de acerto no item i
- ** ∏‚Å±**: Resposta observada (0 ou 1)

#### **Implementa√ß√£o**

```python
def estimate_theta(self, responses: np.ndarray, a_params: np.ndarray, 
                  b_params: np.ndarray, c_params: np.ndarray) -> float:
    """
    Estima a profici√™ncia (theta) de um aluno
    """
    bounds = self.config["theta_bounds"]
    
    # Otimiza√ß√£o com diferentes pontos iniciais para evitar m√≠nimos locais
    initial_points = [-2.0, -1.0, 0.0, 1.0, 2.0]
    best_theta = 0.0
    best_ll = float('inf')
    
    for initial_theta in initial_points:
        try:
            result = minimize_scalar(
                lambda theta: self.log_likelihood(theta, responses, a_params, b_params, c_params),
                bounds=bounds,
                method='bounded',
                options={'xatol': 1e-6}
            )
            
            if result.success and result.fun < best_ll:
                best_theta = result.x
                best_ll = result.fun
                
        except Exception:
            continue
    
    return best_theta
```

### **Tratamento de Respostas Extremas**

#### **Respostas Perfeitas (All Correct)**
- **Problema**: Log-likelihood tende a +‚àû
- **Solu√ß√£o**: Estimativa de theta = limite superior da escala

#### **Respostas Nulas (All Wrong)**
- **Problema**: Log-likelihood tende a +‚àû
- **Solu√ß√£o**: Estimativa de theta = limite inferior da escala

#### **Implementa√ß√£o**

```python
def _handle_extreme_responses(self, responses: np.ndarray, 
                             a_params: np.ndarray, b_params: np.ndarray, 
                             c_params: np.ndarray) -> float:
    """
    Trata respostas extremas (todas corretas ou todas incorretas)
    """
    if np.all(responses == 1):
        return self.config["theta_bounds"][1]  # Limite superior
    elif np.all(responses == 0):
        return self.config["theta_bounds"][0]  # Limite inferior
    else:
        return None  # Resposta normal, usar estima√ß√£o
```

## üîç Valida√ß√£o e Qualidade dos Dados

### **Crit√©rios de Valida√ß√£o**

#### **1. Dados de Entrada**
- **Completude**: M√≠nimo 90% de respostas v√°lidas
- **Consist√™ncia**: Respostas bin√°rias (0/1)
- **Tamanho**: M√≠nimo 10 estudantes, m√°ximo 100.000

#### **2. Par√¢metros dos Itens**
- **a**: 0.1 ‚â§ a ‚â§ 10.0
- **b**: -5.0 ‚â§ b ‚â§ 5.0
- **c**: 0.0 ‚â§ c ‚â§ 0.5

#### **3. Resultados**
- **Theta**: -5.0 ‚â§ Œ∏ ‚â§ 5.0 (5 desvios padr√£o)
- **Nota ENEM**: 0 ‚â§ nota (sem limite m√°ximo, distribui√ß√£o N(500,100))

### **Implementa√ß√£o da Valida√ß√£o**

```python
def validate_data_quality(self, df: pd.DataFrame) -> bool:
    """
    Valida qualidade dos dados de entrada
    """
    # Verificar colunas obrigat√≥rias
    required_cols = ["CodPessoa", "Questao", "RespostaAluno", "Gabarito"]
    if not all(col in df.columns for col in required_cols):
        return False
    
    # Verificar tamanho m√≠nimo
    if len(df) < 50:  # M√≠nimo de respostas
        return False
    
    # Verificar completude
    completeness = 1 - df.isnull().sum().sum() / (len(df) * len(df.columns))
    if completeness < 0.9:
        return False
    
    return True
```

## üìà Escala e Normaliza√ß√£o

### **Convers√£o para Escala ENEM**

#### **F√≥rmula de Convers√£o**

```
Nota ENEM = 500 + 100 √ó Œ∏
```

Onde:
- **500**: Nota base (m√©dia da escala)
- **100**: Fator de escala
- **Œ∏**: Theta estimado na escala log√≠stica

#### **Implementa√ß√£o**

```python
def calculate_enem_score(self, theta: float) -> float:
    """
    Converte theta para escala ENEM usando distribui√ß√£o N(500, 100)
    
    Args:
        theta: Profici√™ncia estimada (escala log√≠stica -5 a +5)
    
    Returns:
        Nota na escala ENEM (sem limite m√°ximo)
    """
    try:
        base = self.config["enem_base"]  # 500 (m√©dia)
        scale = self.config["enem_scale"]  # 100 (desvio padr√£o)
        enem_score = base + scale * theta
        # Apenas limitar o m√≠nimo a 0, sem limite m√°ximo
        return max(0, enem_score)
    except Exception as e:
        self.logger.error(f"Erro no c√°lculo da nota ENEM: {e}")
        return 500.0
```

### **Normaliza√ß√£o dos Par√¢metros**

#### **Padroniza√ß√£o dos Par√¢metros b**

Para facilitar interpreta√ß√£o, os par√¢metros b podem ser normalizados:

```python
def normalize_b_parameters(self, b_params: np.ndarray) -> np.ndarray:
    """
    Normaliza par√¢metros b para m√©dia 0 e desvio padr√£o 1
    """
    mean_b = np.mean(b_params)
    std_b = np.std(b_params)
    
    if std_b > 0:
        normalized_b = (b_params - mean_b) / std_b
    else:
        normalized_b = b_params - mean_b
    
    return normalized_b
```

## üßÆ Otimiza√ß√µes Num√©ricas

### **Algoritmos de Otimiza√ß√£o**

#### **1. L-BFGS-B para Par√¢metros dos Itens**
- **Vantagem**: Eficiente para problemas com restri√ß√µes
- **Aplica√ß√£o**: Calibra√ß√£o de par√¢metros a, b, c
- **Configura√ß√£o**: Bounds espec√≠ficos para cada par√¢metro

#### **2. Brent para Estima√ß√£o de Theta**
- **Vantagem**: Est√°vel para fun√ß√µes unidimensionais
- **Aplica√ß√£o**: Estima√ß√£o de profici√™ncia individual
- **Configura√ß√£o**: Limites [-5, 5] para 5 desvios padr√£o (padr√£o ENEM)

### **Tratamento de Problemas Num√©ricos**

#### **1. Evitar Overflow/Underflow**
```python
def safe_log(self, x: float) -> float:
    """
    Logaritmo seguro para evitar problemas num√©ricos
    """
    return np.log(np.clip(x, 1e-10, 1 - 1e-10))
```

#### **2. M√∫ltiplos Pontos Iniciais**
```python
def estimate_theta_robust(self, responses: np.ndarray, 
                         a_params: np.ndarray, b_params: np.ndarray, 
                         c_params: np.ndarray) -> float:
    """
    Estima√ß√£o robusta de theta com m√∫ltiplos pontos iniciais
    """
    initial_points = [-4.0, -2.0, 0.0, 2.0, 4.0]
    best_theta = 0.0
    best_ll = float('inf')
    
    for initial_theta in initial_points:
        try:
            result = minimize_scalar(
                lambda theta: self.log_likelihood(theta, responses, a_params, b_params, c_params),
                bounds=(-5, 5),  # Escala expandida para 5 desvios padr√£o
                method='bounded'
            )
            
            if result.success and result.fun < best_ll:
                best_theta = result.x
                best_ll = result.fun
                
        except Exception:
            continue
    
    return best_theta
```

## üìä An√°lise de Qualidade dos Itens

### **√çndices de Qualidade**

#### **1. √çndice de Discrimina√ß√£o (a)**
- **Excelente**: a > 1.0
- **Bom**: 0.5 ‚â§ a ‚â§ 1.0
- **Regular**: 0.3 ‚â§ a < 0.5
- **Ruim**: a < 0.3

#### **2. √çndice de Dificuldade (b)**
- **Muito f√°cil**: b < -1.5
- **F√°cil**: -1.5 ‚â§ b < -0.5
- **M√©dio**: -0.5 ‚â§ b ‚â§ 0.5
- **Dif√≠cil**: 0.5 < b ‚â§ 1.5
- **Muito dif√≠cil**: b > 1.5

#### **3. √çndice de Acerto Casual (c)**
- **Aceit√°vel**: c ‚â§ 0.25
- **Alto**: 0.25 < c ‚â§ 0.35
- **Muito alto**: c > 0.35

### **Implementa√ß√£o dos √çndices**

```python
def calculate_item_quality_indices(self, params_df: pd.DataFrame) -> pd.DataFrame:
    """
    Calcula √≠ndices de qualidade dos itens
    """
    quality_df = params_df.copy()
    
    # √çndice de discrimina√ß√£o
    quality_df['discrimination_quality'] = quality_df['a'].apply(
        lambda x: 'Excelente' if x > 1.0 else
                  'Bom' if x >= 0.5 else
                  'Regular' if x >= 0.3 else 'Ruim'
    )
    
    # √çndice de dificuldade
    quality_df['difficulty_quality'] = quality_df['b'].apply(
        lambda x: 'Muito f√°cil' if x < -1.5 else
                  'F√°cil' if x < -0.5 else
                  'M√©dio' if x <= 0.5 else
                  'Dif√≠cil' if x <= 1.5 else 'Muito dif√≠cil'
    )
    
    # √çndice de acerto casual
    quality_df['guessing_quality'] = quality_df['c'].apply(
        lambda x: 'Aceit√°vel' if x <= 0.25 else
                  'Alto' if x <= 0.35 else 'Muito alto'
    )
    
    return quality_df
```

## üî¨ Testes e Valida√ß√£o

### **Testes de Consist√™ncia**

#### **1. Teste de Ajuste do Modelo**
- **Chi-quadrado**: Compara√ß√£o entre frequ√™ncias observadas e esperadas
- **Implementa√ß√£o**: Agrupamento de respostas por faixas de theta

#### **2. An√°lise de Res√≠duos**
- **Res√≠duos padronizados**: Diferen√ßa entre observado e esperado
- **Crit√©rio**: |res√≠duo| < 2.0 para 95% dos casos

#### **3. Teste de Independ√™ncia Local**
- **Hip√≥tese**: Respostas independentes condicionadas ao theta
- **M√©todo**: Correla√ß√£o entre res√≠duos de itens diferentes

### **Implementa√ß√£o dos Testes**

```python
def test_model_fit(self, responses: np.ndarray, thetas: np.ndarray,
                   a_params: np.ndarray, b_params: np.ndarray, 
                   c_params: np.ndarray) -> Dict:
    """
    Testa o ajuste do modelo 3PL
    """
    # Agrupar por faixas de theta
    theta_bins = pd.cut(thetas, bins=5, labels=False)
    
    chi_square_stats = []
    for bin_idx in range(5):
        bin_mask = theta_bins == bin_idx
        if np.sum(bin_mask) > 0:
            bin_responses = responses[bin_mask]
            bin_thetas = thetas[bin_mask]
            
            # Calcular frequ√™ncias esperadas
            expected_probs = np.array([
                self.prob_3pl(theta, a, b, c)
                for theta, a, b, c in zip(bin_thetas, a_params, b_params, c_params)
            ])
            
            # Chi-quadrado
            observed = bin_responses
            expected = expected_probs
            chi_square = np.sum((observed - expected) ** 2 / expected)
            chi_square_stats.append(chi_square)
    
    # Estat√≠stica total
    total_chi_square = np.sum(chi_square_stats)
    df = len(chi_square_stats) - 1
    
    return {
        'chi_square': total_chi_square,
        'degrees_of_freedom': df,
        'p_value': 1 - chi2.cdf(total_chi_square, df),
        'significant': total_chi_square > chi2.ppf(0.95, df)
    }
```

## üé® Interface e Usabilidade

### **Melhorias na Interface (v3.0)**

#### **1. Reorganiza√ß√£o do Processamento TRI**
- **Sub-abas organizadas**: Gr√°ficos, Estat√≠sticas, Correla√ß√µes, Tabela de Dados
- **Navega√ß√£o intuitiva**: Conte√∫do agrupado logicamente
- **Redu√ß√£o de redund√¢ncia**: Elimina√ß√£o de gr√°ficos duplicados

#### **2. Nova Coluna: Percentual de Acertos**
```python
# C√°lculo autom√°tico do percentual de acertos
percentual_acertos = round((acertos / num_items) * 100, 1)
```

#### **3. Corre√ß√£o de IDs Duplicados**
- **Chaves √∫nicas**: Todos os elementos Streamlit com identificadores √∫nicos
- **Preven√ß√£o de erros**: Elimina√ß√£o de conflitos de elementos
- **Estabilidade**: Interface mais robusta e confi√°vel

#### **4. Mensagens Explicativas**
- **Clareza**: Explica√ß√µes sobre onde encontrar theta dos alunos
- **Orienta√ß√£o**: Guias para navega√ß√£o no dashboard
- **Contexto**: Informa√ß√µes sobre o significado dos par√¢metros

### **Estrutura das Sub-abas**

#### **üìä Gr√°ficos Principais**
- Histogramas de distribui√ß√£o (Theta e ENEM)
- Boxplots para an√°lise de variabilidade
- Distribui√ß√£o cumulativa

#### **üìà Estat√≠sticas**
- Estat√≠sticas descritivas detalhadas
- M√©tricas de centralidade e dispers√£o
- Percentis e quartis

#### **üîó Correla√ß√µes**
- Theta vs. Acertos
- Theta vs. ENEM
- Percentual de Acertos vs. ENEM

#### **üìã Tabela de Dados**
- Resultados completos com download
- Ordena√ß√£o por theta
- Explica√ß√£o das colunas

## üìà Relat√≥rios e Visualiza√ß√µes

### **Relat√≥rios Autom√°ticos**

#### **1. Relat√≥rio de Calibra√ß√£o**
- Par√¢metros estimados com erros padr√£o
- √çndices de qualidade dos itens
- Gr√°ficos de informa√ß√£o dos itens
- Testes de ajuste do modelo

#### **2. Relat√≥rio de Aplica√ß√£o**
- Estat√≠sticas descritivas das profici√™ncias
- Distribui√ß√£o das notas ENEM
- An√°lise de consist√™ncia interna
- Compara√ß√£o com normas de refer√™ncia

### **Gr√°ficos Espec√≠ficos**

#### **1. Curva Caracter√≠stica do Item (CCI)**
```python
def plot_item_characteristic_curve(self, a: float, b: float, c: float, 
                                 theta_range: np.ndarray) -> go.Figure:
    """
    Plota a curva caracter√≠stica do item
    """
    probs = [self.prob_3pl(theta, a, b, c) for theta in theta_range]
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=theta_range,
        y=probs,
        mode='lines',
        name=f'Item (a={a:.2f}, b={b:.2f}, c={c:.2f})'
    ))
    
    fig.update_layout(
        title='Curva Caracter√≠stica do Item',
        xaxis_title='Theta (Profici√™ncia)',
        yaxis_title='Probabilidade de Acerto',
        xaxis=dict(range=[-4, 4]),
        yaxis=dict(range=[0, 1])
    )
    
    return fig
```

#### **2. Fun√ß√£o de Informa√ß√£o do Item**
```python
def plot_item_information_function(self, a: float, b: float, c: float,
                                 theta_range: np.ndarray) -> go.Figure:
    """
    Plota a fun√ß√£o de informa√ß√£o do item
    """
    info_values = []
    for theta in theta_range:
        p = self.prob_3pl(theta, a, b, c)
        info = (a ** 2) * p * (1 - p) * ((1 - c) ** 2) / ((p - c) ** 2)
        info_values.append(info)
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=theta_range,
        y=info_values,
        mode='lines',
        name=f'Informa√ß√£o (a={a:.2f}, b={b:.2f}, c={c:.2f})'
    ))
    
    fig.update_layout(
        title='Fun√ß√£o de Informa√ß√£o do Item',
        xaxis_title='Theta (Profici√™ncia)',
        yaxis_title='Informa√ß√£o',
        xaxis=dict(range=[-4, 4])
    )
    
    return fig
```

## üöÄ Considera√ß√µes para Produ√ß√£o

### **Performance e Escalabilidade**

#### **1. Otimiza√ß√µes de Mem√≥ria**
- Processamento em lotes para grandes datasets
- Uso de arrays NumPy em vez de listas Python
- Limpeza autom√°tica de vari√°veis intermedi√°rias

#### **2. Paraleliza√ß√£o**
- Processamento paralelo de m√∫ltiplos alunos
- Uso de multiprocessing para calibra√ß√£o de itens
- Distribui√ß√£o de carga em m√∫ltiplos cores

#### **3. Cache e Persist√™ncia**
- Cache de par√¢metros calibrados
- Persist√™ncia de resultados intermedi√°rios
- Recupera√ß√£o de falhas de processamento

### **Monitoramento e Logging**

#### **1. M√©tricas de Performance**
- Tempo de processamento por item
- Uso de mem√≥ria durante calibra√ß√£o
- Taxa de converg√™ncia dos algoritmos

#### **2. Alertas de Qualidade**
- Par√¢metros fora dos limites aceit√°veis
- Falhas de converg√™ncia na otimiza√ß√£o
- Inconsist√™ncias nos dados de entrada

## üìö Refer√™ncias Bibliogr√°ficas

1. **Birnbaum, A. (1968)**. Some latent trait models and their use in inferring an examinee's ability. In F. M. Lord & M. R. Novick (Eds.), *Statistical theories of mental test scores* (pp. 397-479). Reading, MA: Addison-Wesley.

2. **Baker, F. B., & Kim, S. H. (2017)**. *The basics of item response theory using R*. New York: Springer.

3. **De Ayala, R. J. (2009)**. *The theory and practice of item response theory*. New York: The Guilford Press.

4. **Hambleton, R. K., Swaminathan, H., & Rogers, H. J. (1991)**. *Fundamentals of item response theory*. Newbury Park, CA: Sage.

5. **Lord, F. M. (1980)**. *Applications of item response theory to practical testing problems*. Hillsdale, NJ: Lawrence Erlbaum Associates.

## üîó Links √öteis

- **Documenta√ß√£o oficial**: [Link para documenta√ß√£o]
- **Reposit√≥rio GitHub**: [Link para reposit√≥rio]
- **Issues e suporte**: [Link para issues]
- **Wiki do projeto**: [Link para wiki]

---

**Desenvolvido para a comunidade cient√≠fica e educacional**

*√öltima atualiza√ß√£o: Janeiro 2025 - v3.0*
