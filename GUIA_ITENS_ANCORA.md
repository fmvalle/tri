# üéØ Guia Pr√°tico - Itens √Çncora no Sistema TRI

## üìã O que s√£o Itens √Çncora?

**Itens √¢ncora** s√£o quest√µes que j√° foram calibradas e validadas em aplica√ß√µes anteriores, servindo como refer√™ncia para calibrar novos itens e manter a consist√™ncia da escala entre diferentes aplica√ß√µes de um teste.

### **Por que usar Itens √Çncora?**

- ‚úÖ **Consist√™ncia**: Mant√©m a mesma escala entre aplica√ß√µes
- ‚úÖ **Qualidade**: Valida novos itens usando refer√™ncias conhecidas
- ‚úÖ **Efici√™ncia**: Reduz o n√∫mero de itens a serem calibrados
- ‚úÖ **Padr√£o**: Segue metodologia aceita internacionalmente (ENEM/SAEB)

## üîß Como Implementar no Sistema

### **1. Preparar Arquivo de Itens √Çncora**

#### **Formato CSV:**
```csv
Questao,a,b,c
1,1.23614,3.66465,0.19831
5,0.93375,2.50839,0.21717
9,1.73057,-1.06602,0.16058
14,7.5943,0.41937,0.17211
20,1.83324,-0.62632,0.12133
```

#### **Colunas Obrigat√≥rias:**
- **Questao**: N√∫mero da quest√£o (deve corresponder ao arquivo de respostas)
- **a**: Par√¢metro de discrimina√ß√£o (deve ser > 0)
- **b**: Par√¢metro de dificuldade (recomendado entre -3 e +3)
- **c**: Par√¢metro de acerto casual (recomendado ‚â§ 0.25)

### **2. Crit√©rios de Qualidade para √Çncoras**

#### **Quantidade M√≠nima:**
- **M√≠nimo**: 5 itens √¢ncora por dom√≠nio
- **Recomendado**: 10-15 itens √¢ncora
- **Ideal**: 20% do total de itens

#### **Distribui√ß√£o de Dificuldade:**
- **F√°cil**: 2-3 itens (b < -1.0)
- **M√©dio**: 4-6 itens (-1.0 ‚â§ b ‚â§ 1.0)
- **Dif√≠cil**: 2-3 itens (b > 1.0)

#### **Qualidade dos Par√¢metros:**
- **a ‚â• 0.5**: Discrimina√ß√£o adequada
- **0.1 ‚â§ c ‚â§ 0.25**: Acerto casual aceit√°vel
- **Estabilidade**: Par√¢metros bem estimados

### **3. Uso no Dashboard**

#### **Passo a Passo:**

1. **Acessar Dashboard**: `streamlit run dashboard.py`

2. **Selecionar Fonte**: Escolher "Arquivo de √Çncoras (CSV)"

3. **Upload de √Çncoras**: Fazer upload do arquivo CSV de √¢ncoras

4. **Upload de Respostas**: Fazer upload do arquivo de respostas dos alunos

5. **Calibra√ß√£o**: O sistema automaticamente:
   - Identifica itens √¢ncora
   - Calibra novos itens usando os √¢ncoras como refer√™ncia
   - Valida a qualidade dos par√¢metros estimados

6. **Resultados**: Visualizar par√¢metros com indica√ß√£o de tipo (√¢ncora vs. calibrado)

### **4. Exemplo Pr√°tico**

#### **Cen√°rio:**
- **Prova**: Matem√°tica 3¬∫ ano
- **Total de itens**: 30
- **Itens √¢ncora**: 6 (20% do total)
- **Novos itens**: 24

#### **Arquivo de √Çncoras (`ancoras_MT_3ano.csv`):**
```csv
Questao,a,b,c
3,1.45,-0.8,0.15
7,2.1,0.2,0.12
12,1.8,1.1,0.18
18,0.9,-1.2,0.22
25,1.6,0.5,0.14
29,2.3,1.8,0.16
```

#### **Arquivo de Respostas (`respostas_MT_3ano.csv`):**
```csv
CodPessoa;Questao;RespostaAluno;Gabarito
12345;1;A;A
12345;2;B;B
12345;3;C;A
...
```

#### **Processo:**
1. **Upload**: Ambos os arquivos no dashboard
2. **Calibra√ß√£o**: Sistema calibra itens 1,2,4,5,6,8,9,10,11,13,14,15,16,17,19,20,21,22,23,24,26,27,28,30
3. **Valida√ß√£o**: Verifica qualidade dos par√¢metros estimados
4. **Resultado**: 30 itens com par√¢metros na mesma escala

## üìä Valida√ß√£o e Qualidade

### **1. Verifica√ß√£o Autom√°tica**

O sistema valida automaticamente:

- ‚úÖ **Par√¢metros v√°lidos**: a > 0, 0 ‚â§ c ‚â§ 1
- ‚úÖ **Limites razo√°veis**: -5 ‚â§ b ‚â§ 5, a ‚â§ 10
- ‚úÖ **Consist√™ncia**: Par√¢metros dentro dos padr√µes aceit√°veis

### **2. Indicadores de Qualidade**

#### **Para Itens √Çncora:**
- **Discrimina√ß√£o**: a ‚â• 0.5 (preferencialmente a ‚â• 1.0)
- **Dificuldade**: Distribui√ß√£o equilibrada na escala
- **Acerto casual**: c ‚â§ 0.25

#### **Para Itens Calibrados:**
- **Converg√™ncia**: Otimiza√ß√£o bem-sucedida
- **Estabilidade**: Par√¢metros dentro dos limites esperados
- **Consist√™ncia**: Coer√™ncia com itens √¢ncora

### **3. Relat√≥rios de Qualidade**

O sistema gera relat√≥rios incluindo:

- üìà **Distribui√ß√£o dos par√¢metros**
- üîç **An√°lise de outliers**
- üìä **Compara√ß√£o com padr√µes de refer√™ncia**
- ‚ö†Ô∏è **Alertas de qualidade**

## üö® Problemas Comuns e Solu√ß√µes

### **1. Falha na Calibra√ß√£o**

#### **Sintomas:**
- Par√¢metros com valores extremos
- Mensagens de erro na otimiza√ß√£o
- Resultados inconsistentes

#### **Solu√ß√µes:**
- **Verificar √¢ncoras**: Garantir qualidade dos itens √¢ncora
- **Aumentar √¢ncoras**: Adicionar mais itens de refer√™ncia
- **Ajustar dados**: Verificar qualidade das respostas

### **2. Par√¢metros Extremos**

#### **Sintomas:**
- a > 10 (discrimina√ß√£o muito alta)
- b < -5 ou b > 5 (dificuldade extrema)
- c > 0.5 (acerto casual muito alto)

#### **Solu√ß√µes:**
- **Revisar √¢ncoras**: Verificar se os √¢ncoras s√£o adequados
- **Ajustar bounds**: Modificar limites de otimiza√ß√£o
- **Validar dados**: Verificar qualidade das respostas

### **3. Inconsist√™ncia de Escala**

#### **Sintomas:**
- Par√¢metros b muito diferentes entre aplica√ß√µes
- Theta estimado fora dos limites esperados
- Notas ENEM inconsistentes

#### **Solu√ß√µes:**
- **Padronizar √¢ncoras**: Usar mesmos √¢ncoras entre aplica√ß√µes
- **Verificar calibra√ß√£o**: Recalibrar se necess√°rio
- **Validar processo**: Revisar todo o processo de calibra√ß√£o

## üî¨ Configura√ß√µes Avan√ßadas

### **1. Ajuste de Par√¢metros de Otimiza√ß√£o**

#### **No arquivo `config/settings.py`:**
```python
TRI_CONFIG = {
    "default_a": 1.0,      # Discrimina√ß√£o padr√£o
    "default_b": 0.0,      # Dificuldade padr√£o
    "default_c": 0.2,      # Acerto casual padr√£o
    "theta_bounds": (-4, 4),  # Limites para theta
    "max_iterations": 1000,  # M√°ximo de itera√ß√µes
    "tolerance": 1e-6      # Toler√¢ncia para converg√™ncia
}
```

### **2. Bounds de Otimiza√ß√£o**

#### **Para par√¢metros dos itens:**
```python
# No m√©todo _estimate_item_parameters
bounds = [
    (0.1, 5.0),    # a: discrimina√ß√£o
    (-3.0, 3.0),   # b: dificuldade
    (0.0, 0.5)     # c: acerto casual
]
```

### **3. Crit√©rios de Valida√ß√£o**

#### **Personalizar valida√ß√£o:**
```python
def validate_calibration(self, params_df: pd.DataFrame) -> Dict:
    validation = {
        'valid': True,
        'warnings': [],
        'errors': []
    }
    
    # Crit√©rios personalizados
    if (params_df['a'] > 8).any():
        validation['warnings'].append("Alguns par√¢metros 'a' s√£o muito altos")
    
    if (params_df['b'] < -4).any() or (params_df['b'] > 4).any():
        validation['warnings'].append("Alguns par√¢metros 'b' s√£o extremos")
    
    return validation
```

## üìà Monitoramento e Manuten√ß√£o

### **1. Controle de Qualidade**

#### **M√©tricas a Monitorar:**
- **Taxa de converg√™ncia**: % de itens calibrados com sucesso
- **Qualidade dos par√¢metros**: Distribui√ß√£o dos valores
- **Consist√™ncia**: Estabilidade entre aplica√ß√µes
- **Performance**: Tempo de processamento

### **2. Atualiza√ß√£o de √Çncoras**

#### **Quando Atualizar:**
- **Mudan√ßa de curr√≠culo**: Novos padr√µes educacionais
- **Melhoria de qualidade**: √Çncoras com melhor discrimina√ß√£o
- **Expans√£o de dom√≠nio**: Novas √°reas de conhecimento
- **Valida√ß√£o externa**: Compara√ß√£o com outros sistemas

#### **Processo de Atualiza√ß√£o:**
1. **Avaliar √¢ncoras atuais**: Qualidade e distribui√ß√£o
2. **Identificar lacunas**: √Åreas que precisam de novos √¢ncoras
3. **Selecionar candidatos**: Itens com boa qualidade
4. **Validar**: Comparar com padr√µes de refer√™ncia
5. **Implementar**: Substituir ou adicionar √¢ncoras

### **3. Backup e Versionamento**

#### **Estrat√©gias:**
- **Versionar √¢ncoras**: Controle de vers√£o dos arquivos
- **Backup autom√°tico**: C√≥pia de seguran√ßa antes de mudan√ßas
- **Documenta√ß√£o**: Registrar mudan√ßas e justificativas
- **Testes**: Validar novas configura√ß√µes antes de produ√ß√£o

## üéì Casos de Uso Educacionais

### **1. Avalia√ß√£o Continuada**

#### **Cen√°rio:**
- **Escola**: Aplica√ß√£o trimestral de provas
- **Objetivo**: Acompanhar progresso dos alunos
- **Solu√ß√£o**: Usar mesmos √¢ncoras para manter escala

#### **Benef√≠cios:**
- ‚úÖ **Comparabilidade**: Resultados entre trimestres
- ‚úÖ **Progresso**: Acompanhar evolu√ß√£o individual
- ‚úÖ **Interven√ß√£o**: Identificar necessidades espec√≠ficas

### **2. Avalia√ß√£o Nacional**

#### **Cen√°rio:**
- **Sistema**: ENEM, SAEB, Prova Brasil
- **Objetivo**: Comparar escolas e regi√µes
- **Solu√ß√£o**: Itens √¢ncora padronizados nacionalmente

#### **Benef√≠cios:**
- ‚úÖ **Equidade**: Mesma escala para todos
- ‚úÖ **Transpar√™ncia**: Crit√©rios claros e objetivos
- ‚úÖ **Pol√≠ticas**: Base para decis√µes educacionais

### **3. Pesquisa Educacional**

#### **Cen√°rio:**
- **Estudo**: Efic√°cia de metodologias de ensino
- **Objetivo**: Comparar grupos experimentais
- **Solu√ß√£o**: Testes com itens √¢ncora para controle

#### **Benef√≠cios:**
- ‚úÖ **Validade**: Controle de vari√°veis externas
- ‚úÖ **Confiabilidade**: Medidas consistentes
- ‚úÖ **Generaliza√ß√£o**: Resultados aplic√°veis a outros contextos

## üîç Troubleshooting Avan√ßado

### **1. Debug de Calibra√ß√£o**

#### **Logs Detalhados:**
```python
import logging

# Configurar logging detalhado
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# No processo de calibra√ß√£o
logger.debug(f"Calibrando item {questao}")
logger.debug(f"Respostas v√°lidas: {np.sum(valid_mask)}")
logger.debug(f"Par√¢metros iniciais: {initial_params}")
logger.debug(f"Resultado da otimiza√ß√£o: {result}")
```

#### **Verifica√ß√£o de Dados:**
```python
def debug_item_data(self, responses: np.ndarray, questao: int):
    """
    Debug detalhado dos dados de um item
    """
    print(f"=== Debug Item {questao} ===")
    print(f"Total de respostas: {len(responses)}")
    print(f"Respostas v√°lidas: {np.sum(~np.isnan(responses))}")
    print(f"Taxa de acerto: {np.nanmean(responses):.3f}")
    print(f"Desvio padr√£o: {np.nanstd(responses):.3f}")
    print(f"Valores √∫nicos: {np.unique(responses[~np.isnan(responses)])}")
```

### **2. An√°lise de Converg√™ncia**

#### **Verificar Otimiza√ß√£o:**
```python
def analyze_optimization(self, responses: np.ndarray, questao: int):
    """
    An√°lise detalhada da otimiza√ß√£o
    """
    # Testar diferentes pontos iniciais
    initial_points = [
        [1.0, 0.0, 0.2],   # Padr√£o
        [0.5, -1.0, 0.1],  # Baixa discrimina√ß√£o, f√°cil
        [2.0, 1.0, 0.3],   # Alta discrimina√ß√£o, dif√≠cil
        [1.5, 0.5, 0.15],  # M√©dia discrimina√ß√£o, m√©dio
    ]
    
    results = []
    for i, initial in enumerate(initial_points):
        try:
            result = minimize(self.objective, initial, method='L-BFGS-B',
                            bounds=[(0.1, 5.0), (-3.0, 3.0), (0.0, 0.5)])
            
            results.append({
                'initial': initial,
                'success': result.success,
                'x': result.x,
                'fun': result.fun,
                'iterations': result.nit
            })
            
        except Exception as e:
            results.append({
                'initial': initial,
                'success': False,
                'error': str(e)
            })
    
    return results
```

### **3. Valida√ß√£o Cruzada**

#### **Teste de Estabilidade:**
```python
def cross_validate_anchors(self, responses_df: pd.DataFrame, 
                          anchor_items: Dict, n_folds: int = 5):
    """
    Valida√ß√£o cruzada dos itens √¢ncora
    """
    from sklearn.model_selection import KFold
    
    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)
    
    stability_results = []
    
    for fold, (train_idx, test_idx) in enumerate(kf.split(responses_df)):
        # Dividir dados
        train_df = responses_df.iloc[train_idx]
        test_df = responses_df.iloc[test_idx]
        
        # Calibrar com dados de treino
        train_params = self.calibrate_items_3pl(train_df, anchor_items)
        
        # Validar com dados de teste
        test_quality = self.validate_calibration(test_params)
        
        stability_results.append({
            'fold': fold,
            'train_size': len(train_df),
            'test_size': len(test_df),
            'quality': test_quality
        })
    
    return stability_results
```

## üìö Recursos Adicionais

### **1. Bibliotecas Recomendadas**

#### **Para An√°lise Avan√ßada:**
```bash
pip install mirtpy          # Calibra√ß√£o TRI avan√ßada
pip install pyirt           # Implementa√ß√£o TRI em Python
pip install irt             # Teoria de resposta ao item
pip install psychometric    # An√°lise psicom√©trica
```

#### **Para Visualiza√ß√µes:**
```bash
pip install plotly          # Gr√°ficos interativos
pip install seaborn         # Visualiza√ß√µes estat√≠sticas
pip install matplotlib      # Gr√°ficos b√°sicos
```

### **2. Refer√™ncias T√©cnicas**

- **Baker, F. B. (2001)**. *The basics of item response theory*
- **De Ayala, R. J. (2009)**. *The theory and practice of item response theory*
- **Hambleton, R. K. et al. (1991)**. *Fundamentals of item response theory*

### **3. Ferramentas de Valida√ß√£o**

- **R**: Pacotes `mirt`, `ltm`, `irtoys`
- **Python**: Bibliotecas mencionadas acima
- **Software comercial**: BILOG, PARSCALE, MULTILOG

## üéØ Checklist de Implementa√ß√£o

### **‚úÖ Prepara√ß√£o:**
- [ ] Selecionar itens √¢ncora de qualidade
- [ ] Verificar distribui√ß√£o de dificuldade
- [ ] Validar par√¢metros dos √¢ncoras
- [ ] Preparar arquivo CSV no formato correto

### **‚úÖ Implementa√ß√£o:**
- [ ] Upload de √¢ncoras no dashboard
- [ ] Upload de dados de respostas
- [ ] Executar calibra√ß√£o com √¢ncoras
- [ ] Verificar resultados da calibra√ß√£o

### **‚úÖ Valida√ß√£o:**
- [ ] Verificar qualidade dos par√¢metros
- [ ] Analisar distribui√ß√£o dos resultados
- [ ] Comparar com padr√µes de refer√™ncia
- [ ] Documentar processo e resultados

### **‚úÖ Manuten√ß√£o:**
- [ ] Monitorar qualidade ao longo do tempo
- [ ] Atualizar √¢ncoras quando necess√°rio
- [ ] Manter backup e versionamento
- [ ] Treinar usu√°rios no sistema

---

**Este guia deve ser usado em conjunto com a documenta√ß√£o t√©cnica completa do sistema.**

*Para d√∫vidas t√©cnicas, consulte `DOCUMENTACAO_TECNICA.md`*
*Para suporte geral, consulte `README.md`*
